<comments><comment><videoId>4KQhGY51i8o</videoId><authorChannelId>UChBADDIselnEyjE_NFoLxlw</authorChannelId><textDisplay>volumetric caustics vs moire patterns,..- optimal transport vs indexing families of curves and Fourier transforms,..- you should check put graph neural networks, differential/smooth cellular automata, and hypergraph stuff wolfram has (note Im still looking into hypermaps as they are more powerful but its way above me right now). Oh also a paper on geometric algerbra (Clifford algebras) for AI recently came out. You being in pure maths im sure you could widdle down rather its a viable approach for the future of this stuff man. Also earned a sub with this one. Looking forward to the binge bro.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>Idk what that is but topic suggestions are exactly the kind of comments I&#8217;m looking for. Thank you &#129761;</textDisplay></reply><reply><authorChannelId>UChBADDIselnEyjE_NFoLxlw</authorChannelId><textDisplay>oh also Growing Neural Cellular Automata&lt;br&gt;Differentiable Model of Morphogenesis</textDisplay></reply></replies></comment><comment><videoId>4KQhGY51i8o</videoId><authorChannelId>UCgBjnZ7_qTYau3If4Aqkbig</authorChannelId><textDisplay>Given how holographic representation has conceptual similarities with frequency transforms (like Fourier), and that various kinds of frequency transforms have been used in neural nets,  I am wondering if it would be useful for you to explore a question like this: what happens if I apply the principles of holographic representation to how frequency transforms are used in some neural nets.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hmmm can&amp;#39;t tell if I&amp;#39;m not quite understanding your proposal or if it&amp;#39;s still just too vague to count as a testable hypothesis yet. It might be the former since I&amp;#39;m still not very familiar with the theoretical math behind holograms which means that while I do see the conceptual connection, I can&amp;#39;t quite connect the math in my head to that of fourier analysis. However I love the direction you&amp;#39;re going with this so pls feel free to dump your thoughts any time, that&amp;#39;s what my channel is for. Going to make a note to come back to this once I learn more theory behind holograms broadly rather than the specific linear algebra application performed here</textDisplay></reply></replies></comment><comment><videoId>4KQhGY51i8o</videoId><authorChannelId>UCn1EwxWd7st-eGecNmNtTIw</authorChannelId><textDisplay>Tldr?</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>haha if you want a tldr then I don&amp;#39;t think my channel is going to be for you. I&amp;#39;ll consider changing my mind on that though depending on future circumstances</textDisplay></reply><reply><authorChannelId>UCn1EwxWd7st-eGecNmNtTIw</authorChannelId><textDisplay>@@Tunadorable bro what come on it ain&amp;#39;t that deep &#128557;</textDisplay></reply></replies></comment><comment><videoId>4KQhGY51i8o</videoId><authorChannelId>UCZwss_6zfKmKUdU9s51f3sg</authorChannelId><textDisplay>I have had a copy of this paper for a good while, I think it&#8217;s a great idea to go back to the work that was being done in the 80s as well to get a better understanding of these systems but I doubt there is one old paper with the answers just waiting for someone to find, for that you will need to look into the neuroscience of it all probably &#129335;</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>Hmmmm I see what you&amp;#39;re saying, I think you&amp;#39;re right that the answer is ~likely~ not just lying around to be found, but I don&amp;#39;t think it&amp;#39;s an impossibility given how long google just sat on the transformer architecture and let OpenAI run away with it a few years later. This statement is less true for the field of AI given how bustling it is and the fact that everything gets posted to ArXiv, but a lot of research out there in academia really doesn&amp;#39;t get read much if at all. More importantly, what I find valuable in reading older papers is not the explicit ideas that they had at the time, but moreso the potential that we in the present may have new interesting ideas that can spring off of what they might&amp;#39;ve assumed was a dead end. Thanks for the input!</textDisplay></reply></replies></comment><comment><videoId>4KQhGY51i8o</videoId><authorChannelId>UCABA-59VI8bXh-dVU7OhA4Q</authorChannelId><textDisplay>Good work!</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>Thanks! lmk if in the future there&amp;#39;s any specific topics you&amp;#39;d be interested in me covering</textDisplay></reply><reply><authorChannelId>UCABA-59VI8bXh-dVU7OhA4Q</authorChannelId><textDisplay>@@Tunadorable anything related to consciousness is interesting, especially the latest papers</textDisplay></reply></replies></comment><comment><videoId>4KQhGY51i8o</videoId><authorChannelId>UCA7DJ_L-QkUdOUE79sNwCAg</authorChannelId><textDisplay>That&amp;#39;s so cool, this should have much more views, i think it&amp;#39;s something that should be much more widespread</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>haha thanks honestly the goal isn&#8217;t even to get views it&#8217;s just to force myself to study. fingers crossed that views happen too tho that&#8217;d be fun. lmk if there&#8217;s any specific topics you&#8217;d be interested in me keeping an eye on</textDisplay></reply></replies></comment><comment><videoId>2PiMYxxAlDI</videoId><authorChannelId>UCZwss_6zfKmKUdU9s51f3sg</authorChannelId><textDisplay>interesting, I think we have learned a lot about generalization since this paper was published, how are you deciding which papers are worth reading? is there somthing specific you are looking for?</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>so I construct my list from 1) papers I find interesting from my daily look-through of the newest publications to arXiv, 2) papers on topics I&amp;#39;m interested in that I found through search and 3) older but important papers that I read in order to build foundation and make sure I&amp;#39;m not missing anything obvious. As far as the order, it&#8217;s just whatever strikes my fancy on a given day. &lt;br&gt;&lt;br&gt;You raise a good point though, in the future I&amp;#39;ll try and be more clear when I&amp;#39;m reading an older paper and what that might mean for interpreting its conclusions. &lt;br&gt;&lt;br&gt;Thanks for taking an interest! Been very busy with life and I&amp;#39;m hoping to up the quantity soon</textDisplay></reply></replies></comment><comment><videoId>JHkN6Z5_Jn8</videoId><authorChannelId>UCH_v_8na5YCMNx_F1yuI34Q</authorChannelId><textDisplay>yes! I was looking for something like this - I remember vaguely reading this was some kind of problem that kept AI from getting any better for decades.  Thanks!</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>glad you liked it!</textDisplay></reply></replies></comment><comment><videoId>nO-OxduSwNs</videoId><authorChannelId>UCKv_EugPMoiue4fGvgKy70A</authorChannelId><textDisplay>Yeah the thing I don&amp;#39;t like about the &amp;quot;brain in a vat&amp;quot; critique is that in my opinion it assumes an anthropogenic &amp;quot;body&amp;quot; and sensory experience.&lt;br&gt;&lt;br&gt;The way that a computer-based intelligence would perceive the world would likely be through a set of senses we don&amp;#39;t necessarily know.&lt;br&gt;&lt;br&gt;Pretty much exactly what you mentioned with interface theory. Any sensory experience we percieve is ultimately a compressed, filtered, and obscured. They develop based on fitness not accuracy.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>yes!!! you sound already familiar with the idea but if you want some mind blowing evidence check out my video called Truth Behind the Trip or any of Donald Hoffman&#8217;s podcasts or papers</textDisplay></reply></replies></comment><comment><videoId>dWSc4e_o1iU</videoId><authorChannelId>UCDsZGFwtdEJ91wqN-AiuGCg</authorChannelId><textDisplay>Recursion of summaries as consciousness?</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>Thought is not fully formed in my head yet, very tip-of-my tongue. The best I can get to describing it rn is that consciousness is a learning algorithm that involves modeling (perceiving) one&#8217;s self and one&#8217;s effect on the environment in order to better fit the loss function. Therefore we need to give the model a little nudge where we make its own output part of its training environment</textDisplay></reply></replies></comment><comment><videoId>kBAVP0zWfPM</videoId><authorChannelId>UCRiT-S-T6SsLJ3JxcLDWKJw</authorChannelId><textDisplay>No they don&amp;#39;t</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>Oh shit u right</textDisplay></reply></replies></comment><comment><videoId>kBAVP0zWfPM</videoId><authorChannelId>UC5Ve3juAnyMLUudSNATg6UA</authorChannelId><textDisplay>I&amp;#39;ve been suspecting this could occur even in high dimensional spaces. I had been trying to create a test fractal loss function but kept running into issues though. I&amp;#39;ve also been toying around with modifying gradient descent, I hope we don&amp;#39;t have the same idea lol.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>Hahahah I hope we do have the same idea and can co-author so there&amp;#39;s less work for us both! Hop in the discord I&amp;#39;d love to discuss. I do have another video about my idea but it was really a lazy attempt at hoping this would be the case for a simple GPT-2 model even though I had reason to believe that wouldn&amp;#39;t work. I&amp;#39;m aiming to post a video and finish training a simple language model that exhibits fractal patterns in the embedding space, so be on the lookout for that.</textDisplay></reply><reply><authorChannelId>UC5Ve3juAnyMLUudSNATg6UA</authorChannelId><textDisplay>@@Tunadorable I&amp;#39;m part of a research lab(probably should&amp;#39;ve commented on my professional account but whatever) and they&amp;#39;d probably be concerned about something like this getting scooped if I posted it in a Discord. As such, I&amp;#39;ll have to decline. I haven&amp;#39;t put too much work into properly formalizing the idea due to being busy with other research though, so if we do have the same idea, you&amp;#39;ll probably beat me to it. I wish you luck in your endeavor though! Statistically speaking, our ideas are probably very different anyways.</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>Hahaha great to hear! If you&amp;#39;d like to join the discord and just discuss AI topics casually rather than giving away proprietary information feel free to do so. Actually hoping to get hired by a research lab myself in a few months so I envy you!</textDisplay></reply><reply><authorChannelId>UC5Ve3juAnyMLUudSNATg6UA</authorChannelId><textDisplay>@@Tunadorable I&amp;#39;m actually a student in an AI lab, so I&amp;#39;m not actually employed by the lab, just a member doing research. I&amp;#39;ll consider the invite though!</textDisplay></reply></replies></comment><comment><videoId>kBAVP0zWfPM</videoId><authorChannelId>UCreEwqXawASORfKL53ipqYg</authorChannelId><textDisplay>I don&amp;#39;t really get the discussions in the comments, it seems reasonable to me that equations like (2) could be nondifferentiable! Also, fractals don&amp;#39;t have to hold to all scales, so even on truncating (2) to a finite sum you still could have difficulties differentiating. Basically even if it is not strictly nondifferentiable, you could still have (f(x+h)-f(x))/h returns garbage data for 1e-10&amp;lt;h&amp;lt;1. This is the same reason why you can claim various real world objects are fractal despite being made of atoms, you just have some range of length scales where your system exhibits fractal structure, and you allow the fractal dimension to depend on length scale.&lt;br&gt;&lt;br&gt;But IMO we should still be perfectly happy to do the experimental mathematics, &amp;quot;just do it with millions of dollars of compute and see if it works,&amp;quot; though. Differentiability isn&amp;#39;t something I expect to be at the heart of why modern giant ML models are smart, but maybe that&amp;#39;s a radical position? I dunno, I did grad school for physics not ML lol.&lt;br&gt;&lt;br&gt;Yknow what I&amp;#39;m going to add something to my weekend project list: &amp;quot;Experimentally run gradient descent approximations on various fractal functions like f(x)=\sum_{n=0}^{\infty} 2^(-n) cos(3^n x)&amp;quot; :D</textDisplay><replies><reply><authorChannelId>UCreEwqXawASORfKL53ipqYg</authorChannelId><textDisplay>also subscribed and thumbed up thanks for posting this and stimulating discussion!</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>yooooo if you run that experiment PLEASE join my discord and talk about it that&amp;#39;d be so hype. thanks for the amazing comment happy to have you!</textDisplay></reply></replies></comment><comment><videoId>kBAVP0zWfPM</videoId><authorChannelId>UCQKbzFNT1Qvh4pFNUshlrXw</authorChannelId><textDisplay>I think the loss landscape may have a fractal landscape when you feed the output or a function of the output of the network into itself in a closed loop, so that you form a chaotic system. I didn&amp;#39;t really understand what you meant when you said previously that the loss landscape was fractal in nature, because I thought you were talking about non-looping neural networks (which have bounded output gradients and therefore cannot be fractal, although still probably very complex), but now I realize that they can indeed be fractal in nature if the form closed loops. Well predicted.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hahaha yes I definitely wasn&amp;#39;t fully connecting all the dots when I glazed over the recursion part. The fractal loss landscape idea initially came to me in reference to an architecture design idea I had (a much newer and significantly different version of my triple hierarchical GPT decoder video) which does include recursion. My attempt to look for the same phenomenon in GPT-2 was misguided insofar as GPT2 lacks said recursion and I was overlooking that, essentially unrealistically hoping to find a shortcut to a cool result. Anyways, be on the lookout for the next version of that architecture. It incorporates a kind of recursion as well as some ideas from my hypersphere video, and I&amp;#39;m very optimistic about both its capabilities and what it might teach us about how these models work. Haven&amp;#39;t even written out the PyTorch layers yet though so still definitely at least a month away from a final product. Thanks for watching!!!!</textDisplay></reply><reply><authorChannelId>UCQKbzFNT1Qvh4pFNUshlrXw</authorChannelId><textDisplay>@@Tunadorable What do you think of the idea to use synthetic gradients for backpropagating through recurrent layers in order to smooth out the loss landscape? The technique seemed very promising when it came but it didn&amp;#39;t seem to catch on as I don&amp;#39;t think I have seen a single application of it.</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>I wasn&amp;#39;t aware the of the term &amp;quot;synthetic gradient&amp;quot; until asking chatGPT just now but yes it&amp;#39;s fs something I&amp;#39;m interested in. The possibility had occurred to me months ago (as I always seem to claim :P) but I only became aware of it actually in practice when I stumbled upon &lt;a href="https://arxiv.org/abs/2310.18191"&gt;https://arxiv.org/abs/2310.18191&lt;/a&gt; which I have not read, although from a GPT summary I seem to remember the results being underwhelming. Definitely something I&amp;#39;ll be looking into in the future though, I do think it has some potential if executed properly. You should join the discord! link in description</textDisplay></reply><reply><authorChannelId>UCQKbzFNT1Qvh4pFNUshlrXw</authorChannelId><textDisplay>@@Tunadorable Hm, I haven&amp;#39;t read it either, but it seems to be about a another (but also interesting) concept where they train train a neural network to act as an optimizer and update the weights of another network, and I can&amp;#39;t find any mention of synthetic gradients in it. The work I&amp;#39;m referring to is this: &lt;a href="https://deepmind.google/discover/blog/decoupled-neural-interfaces-using-synthetic-gradients/"&gt;https://deepmind.google/discover/blog/decoupled-neural-interfaces-using-synthetic-gradients/&lt;/a&gt;</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>Ok so I just read that link, it seems to me like the concepts are intricately related. Deepmind trained a simple model that can look at a small local portion of a network and predict a local gradient for that layer, whereas the velo model looks at an entire model and acts as a complete optimization algorithm replacement. So as far as I can tell they&amp;#39;re doing the essentially same thing, but either looking at the model globally vs locally. Cool stuff</textDisplay></reply></replies></comment><comment><videoId>kBAVP0zWfPM</videoId><authorChannelId>UCH4YpDkdBe1HfbNbWQmdlEA</authorChannelId><textDisplay>Hi! You did not complete your video SEO thets why your channel is not increasing. If you want I can help you to grow your channel. I know how to grow a channel as a digital marketer.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>thank you for your concern but I&amp;#39;ve got some close friends who are high end yt consultants so I&amp;#39;m all good. I appreciate it though!</textDisplay></reply></replies></comment><comment><videoId>soKGo3pIb1c</videoId><authorChannelId>UCKuZbtX78pw3NSe_BMrs3Hg</authorChannelId><textDisplay>I don&amp;#39;t know if I&amp;#39;m qualified here to say this but I think that there is some similarity in this, to the question of whether every person sees the same color red. One can argue that as other colors behave distinctly in comparison to the color red, we can export the experience of seeing color red to another person and have the same experience withouth having to understand what red is like but by just understanding that the color red behaves similarly enough in the other person. This video in youtube discussed this a bit in a hand wavy way: &amp;quot;Category Theory for Neuroscience (pure math to combat scientific stagnation)&amp;quot;. I haven&amp;#39;t really thought this trough yet but I thought that maybe it would be interesting to you.&lt;br&gt;&lt;br&gt;I&amp;#39;m currently of the opinion that the main thing is the sentience at the center of it all and the rest is just an input stream that comes in. Consciousness is just the resolution and some filters applied to the input stream. I&amp;#39;m very inconfident in that the human consciousness is any &amp;quot;better&amp;quot; than the others. It does seem to be more complicated though. Good for building consistent models of reality.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hahaha no need to be qualified for anything here, all speculation is welcome! totally interesting point, ill check out that video at some point</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>Just watched the video, SO COOL!!! Love that I can now argue against every single stoner who brings up the color inversion possibility :P You don&amp;#39;t seem very confident in your interpretation so just fyi I majored in math and I want you to know as far as I can tell you&amp;#39;re totally on a valid interpretation of that video. Thanks for the rec!!!!!</textDisplay></reply></replies></comment><comment><videoId>soKGo3pIb1c</videoId><authorChannelId>UCfW3bcCYoHJGJ87fLEMKQsQ</authorChannelId><textDisplay>I love the concept of this video. I&amp;#39;m inspired (almost) to start a series about Merleau-Ponty.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>do it!</textDisplay></reply></replies></comment><comment><videoId>soKGo3pIb1c</videoId><authorChannelId>UCZT85ZsCOaXdLDXdZVNQvuw</authorChannelId><textDisplay>&lt;a href="https://www.youtube.com/watch?v=soKGo3pIb1c&amp;amp;t=7m33s"&gt;7:33&lt;/a&gt; Totally! This is because everyone&amp;#39;s conciousness develops based on the various things they experienced, and how they felt emotionally through each experience</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>yooooo interesting idea of causation there. ofc the nature vs nurture argument here is even more difficult to tease out than normal given that we&#8217;re talking about consciousness. i&#8217;d love to see a study done where psychologists ask people a bunch of questions like &#8220;do you dream in color,&#8221; &#8220;when you think/read do you just somehow know or is there an actual audible voice in your head,&#8221; etc and then correlate that with IQ, life experiences, etc. very insightful point you&#8217;ve made, thanks!</textDisplay></reply></replies></comment><comment><videoId>soKGo3pIb1c</videoId><authorChannelId>UCZT85ZsCOaXdLDXdZVNQvuw</authorChannelId><textDisplay>I haven&amp;#39;t watched the video yet, but I think so 100%... The more intelligent you are, the more self-aware you are, and the more self-aware you are, the higher level of conciousness you exibit...&lt;br&gt;This is why stupid people lack common sense and basic social awareness</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hmmmm i could see a high correlation but id also like to point out the trap of rationality. logic tends to fall in love with its own creation, and to that end ive also seen exceptions to your observation where highly intelligent people lose touch with reality when they fall into the vortex of a thought loop. i also tend to generally shy away from any claims that would imply smart/stupid people are inherently morally better/worse. every tool is a double edged sword, and intelligence is the thing that uses tools</textDisplay></reply></replies></comment><comment><videoId>soKGo3pIb1c</videoId><authorChannelId>UCRyw5y4tjejS6aBLK9PqXog</authorChannelId><textDisplay>I think consciousness is strictly our global biological response mechanism, with pain being a high signal feedback. Awareness is just all the lights on our dashboard.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>i can&#8217;t remember what i said in the video but i think our viewpoints are similar. if i did say it then i probably conveyed it as &#8220;self-awareness is a training mechanism,&#8221; meaning that our ability to be aware of our own conscious experience developed in order to help us change said experience and the behaviors downstream of it so that we could more quickly adapt to change. i also agree that pain is a learning mechanism, although i think it came about earlier in the evolutionary process than self-awareness. it seems to me most life forms on earth experience pain but most do not exhibit signs of self-awareness</textDisplay></reply></replies></comment><comment><videoId>soKGo3pIb1c</videoId><authorChannelId>UC3v0AnzwgEoFXcipIbY_v2w</authorChannelId><textDisplay>Isn&amp;#39;t consciousness only the ability to reflect on the past? each moment is learning and changing circuits or reinforcing, that&amp;#39;s consciousness.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hmmmm interesting definition. when someone gets full amnesia, are they not yet conscious for the first second that they&#8217;re awake post getting said amnesia? for someone who has the type of amnesia that prevents them from recording any short term memory so that they&#8217;re constantly living in the moment, what would that mean for your definition? i think you bring up a very interesting quality/flavor/subcomponent of our conscious experience as humans but i&#8217;m not necessarily convinced that it is the defining aspect of consciousness nor even necessary for a conscious experience. really great thought though, i&#8217;d love to have a good word that adequately conveys the importance of the thing you&#8217;re describing</textDisplay></reply></replies></comment><comment><videoId>soKGo3pIb1c</videoId><authorChannelId>UC3v0AnzwgEoFXcipIbY_v2w</authorChannelId><textDisplay>you need to have a kid to understand how smart they are. the only reason they cry is because they don&amp;#39;t yet have the circuits to communicate what they want. They share, they care, they react and they have answers to questions in every year of their lives. They are conscious from the moment they are born but they are locked out of abilities until they grow up.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>yes certainly i&#8217;m not saying they&#8217;re not conscious, i&#8217;m saying that the progressively changing inner structure that results in those abilities can be interpreted as jumping up levels of consciousness. I appreciate your take and totally think it&#8217;s a valid criticism of what i said given the lackluster way i conveyed it, so thanks! need more comments like this to help me clarify my thoughts</textDisplay></reply></replies></comment><comment><videoId>soKGo3pIb1c</videoId><authorChannelId>UCvZveVfJixYSjKdE1BGOynw</authorChannelId><textDisplay>The thought that the experience of consciousness is very different from person to person is mind boggling.  The opposite always seemed so self evident to me, that I never considered it.</textDisplay><replies><reply><authorChannelId>UCJS6Gz-6mzxoW3ugR2qXbuQ</authorChannelId><textDisplay>Most humans don&amp;#39;t actually experience consciousness. They&amp;#39;re NPCs.</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hahahaha i highly recommend sitting down with a friend and asking them questions like: are your dreams in color? when you remember something do you just know it or do you literally see it? when you think and read do you have an &#8220;audible&#8221; voice in your head and if so who does it sound like? if you had to point to &#8220;yourself,&#8221; would you point towards your eyes, deeper in your head, your heart, your entire body as a whole, etc?</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>this is a hilarious and very common take thanks to tiktok right now but my personal belief is that people of sufficiently different flavors and types of consciousness have trouble syncing with each other because your frequency is so different. it&#8217;s important to do your best to imagine how different their experience must be and how that effects your ability to kind of empathize or have a theory of mind of them rather than assuming that their form of consciousness is somehow lesser.</textDisplay></reply><reply><authorChannelId>UCJS6Gz-6mzxoW3ugR2qXbuQ</authorChannelId><textDisplay>@@Tunadorable Stop peddling bs. True conscious self-aware beings are incredibly rare. The vast majority of humans are like NPCs in video games; they never attain consciousness beyond something comparable to other animals. This is an obvious phenomenon. You can very often easily tell when people are empty NPC types because it&amp;#39;s just like being able to distinguish real players in video games from NPCs.</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>@@JustinWilliams-ed2ug lmao so you&amp;#39;re some kind of a higher level being with self-awareness and most of the people around you are inferior lower life forms incapable of interesting free thought or something? Hopefully I&amp;#39;m misinterpreting your point there, and I&amp;#39;m open to that possibility. But if my appraisal is accurate, then that&amp;#39;s not a very healthy way to approach your human relationships. Feel free to disagree but I believe it&amp;#39;s always best to assume that I don&amp;#39;t know the first thing about what&amp;#39;s going on and that other people may know and experience different and valuable things; that I could learn from them if I give them the chance to change my mind, which I&amp;#39;d be happy for you to do to me right now if you&amp;#39;re right.&#160;&lt;br&gt;&lt;br&gt;I&amp;#39;d like to suggest that maybe you&amp;#39;re just not very good at asking the right questions in conversation to tease out people&amp;#39;s true thoughts, feelings, personalities, etc? Maybe they&amp;#39;re just as much of a main character as you are but neither of you have a high enough speech skill to convey to each other how exactly you&amp;#39;ve chosen to approach skill progression in this RPG.&#160;&lt;br&gt;&lt;br&gt;I appreciate your obvious passion about the subject though as well as the video engagement and look forward to the possibility of being persuaded to your argument</textDisplay></reply></replies></comment><comment><videoId>soKGo3pIb1c</videoId><authorChannelId>UCjBdzGNNcm0lolmdxnp9A0A</authorChannelId><textDisplay>Super cool to see this type of content on Youtube. Thanks</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hahaha happy to do it!</textDisplay></reply></replies></comment><comment><videoId>soKGo3pIb1c</videoId><authorChannelId>UCZwss_6zfKmKUdU9s51f3sg</authorChannelId><textDisplay>Thanks for the breakdown, have you considered doing a chronological study of the subject as in starting from Frank Rosenblatt or early neuroscience?</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>Not quite the avenue I&amp;#39;m going down for my own research but that&amp;#39;s a good idea, might gain some valuable insights. Check out my video called &amp;quot;Will AI be Conscious????&amp;quot; for a thorough walkthrough of all the consciousness theories that come from a materialist / computational functionalism background. I appreciate you adding to the conversation!</textDisplay></reply><reply><authorChannelId>UCZwss_6zfKmKUdU9s51f3sg</authorChannelId><textDisplay>@@Tunadorable I did see that, I have meaning to have a look at that one, I&#8217;ll have a look when I have the time next, cheers</textDisplay></reply></replies></comment><comment><videoId>amuI9Gq4aps</videoId><authorChannelId>UC88CWwBsfKY6RDHXw5pxY-Q</authorChannelId><textDisplay>Its not AI, a powerful look up code is not artificial intelligence, Thats all these codes are 0`s and 1`s.Not intelligent, work`s to software rules , etc, etc, get an education.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hahahaha my first non-constructive critic, welcome! if you can&#8217;t draw the connection between this simple toy-case of emergence and emergent properties in other computational domains then i suggest sticking around and watching more of my channel so that you can learn, i&#8217;d love to have you!</textDisplay></reply><reply><authorChannelId>UChZarVzmIqCCy30YRZBNtUA</authorChannelId><textDisplay>It&amp;quot;s not consciousness, a powerful web of synapses is not inteligence, Thats all these minds are just analog chemical signals. Not intelligent. Just using the laws of physics etc, etc, etc, get an education.</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>wow so excited to finally be relevant enough on youtube to receive nonsensical haters! actually are you haters, or just one single hater with two accounts or a bot copying the first person? whichever it is, your incoherence and writing style really gives it away. anyways i&#8217;m gonna take a screenshot of this convo and frame it for memories &#10084;&#65039; not kidding i&#8217;m so legitimately excited&lt;br&gt;&lt;br&gt;out of respect, here&#8217;s the best counter argument that my uneducated (if we&#8217;re not counting my degree in math &amp;amp; psychology) brain can muster on the topic of computation, emergence, intelligence and consciousness: &lt;br&gt;my dad can beat up ur dad!!!!!</textDisplay></reply><reply><authorChannelId>UChZarVzmIqCCy30YRZBNtUA</authorChannelId><textDisplay>@@Tunadorable Dude I was commenting on him not on you. I tried to turn his argument of emergent properties cannot come from simple mathematics to the real world of our emergent mind from simple chemistry. I am on your side. I purposefully kinda copyished his idiotic comment to show how dumb he is. Get it now ? It was obviously joke on him. To be absolutely sure I am certain about emergent properties of AI.</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hahaha sorry that legitimately flew way over my head. got a bit too caught up in the hype of my first haters. my b!</textDisplay></reply></replies></comment><comment><videoId>amuI9Gq4aps</videoId><authorChannelId>UCQWTRmzhQ-fbLyc06la5Fvg</authorChannelId><textDisplay>Holy shit.. I&#8217;m glad this video was recommended to me.  Will  try to come back and watch and give a bit  of my own analysis.  Anyways really interesting channel  and way to  gain  knowledge. It&#8217;s going to  be amazing to see how far  you learn to when  you just started</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>thanks!</textDisplay></reply></replies></comment><comment><videoId>TsCSCCZwkLU</videoId><authorChannelId>UCD-KYlRa4tKcuKE0UNhKxXw</authorChannelId><textDisplay>The paper concludes &amp;quot;These results add nuance to ongoing debates about whether generative models can learn more than just &amp;#39;surface&amp;#39; statistics.&amp;quot; 
&lt;br&gt;I think they accomplish this goal, showing that extrapolation of at least a rudimentary model of 3D space is utilized by LDMs.
&lt;br&gt;However, assuming this is true, I don&amp;#39;t think the dichotomy between statistics and modeling holds. I don&amp;#39;t think it follows that one must &amp;quot;surpass statistics&amp;quot; to create the model. In fact, I think what has been shown is that statistics are sufficient to produce said models, just not merely &amp;#39;surface&amp;#39; level statistics, although this terminology may be vague. &lt;br&gt;If we assume that this is not qualitatively different from the kind of modeling going on in the brain, it follows that the models used by the brain are similarly reducible to statistics. (However we may want to distinguishing between unconscious models like that which the cerebellum uses to help us balance and mental models like using the &amp;quot;Mind Palace&amp;quot; memory technique to visualize a space in one&amp;#39;s minds eye, as I&amp;#39;m unsure how qualia would be reducible to statistics, or what that would even mean.)&lt;br&gt;&lt;br&gt;The possible critique of this view which springs to mind is Penrose&amp;#39;s view that G&#246;del&amp;#39;s Incompleteness theorems demonstrate human&amp;#39;s ability to reason independent of any formal axiomatic system, as we are easily able to see that G&#246;del sentences are unprovable, even if the formalism itself cannot.&lt;br&gt;That said, this may be possible to solve if we consider that we are able to work not merely within the space of only one formalism, but within the set of all possible formalisms and compare them with model theoretic rules of inference, like parsimoniousness and the like. Does this ability fall within the set of computable functions? I wish I knew.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>you had me vigorously agreeing at the first paragraph and then totally lost me on the second &#128514; thanks for the top quality comment! would love to have you join my discord server to discuss more, link on my channel page</textDisplay></reply></replies></comment><comment><videoId>TsCSCCZwkLU</videoId><authorChannelId>UCCm5Ertqqfxvk7gdkSqTQpA</authorChannelId><textDisplay>Perhaps an &#8220;actual model of the world&#8221; or &#8220;understanding&#8221; is simply incredibly dense and complex statistical interrelations between a large number of first-second-x-ordered factors.&lt;br&gt;&lt;br&gt;For example, what does my brain do when I ask the question, &#8220;what if I push this ball this way down the hill?&#8221;&lt;br&gt;&lt;br&gt;It activates a cascade of predictive events in the mind. Aka a deeply-interlinked statistical model with many levels of indirection.&lt;br&gt;&lt;br&gt;You can &#8220;see the Rube Goldberg machine run&#8221; without actually running it.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>great point here, it totally could be statistics all the way down with modeling just being an emergent high level property of combining hella correlations</textDisplay></reply></replies></comment><comment><videoId>TsCSCCZwkLU</videoId><authorChannelId>UCx8YAjm1AHMPETHJoacIlgQ</authorChannelId><textDisplay>Can you share with us a link or the file of this paper?</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>yes it&#8217;s in the description. thanks for watching!</textDisplay></reply></replies></comment><comment><videoId>6USl795b6D4</videoId><authorChannelId>UCIyYQ-PL6J13_-g57KxvFKg</authorChannelId><textDisplay>Thanks for this great comment!&#128075; Use a multimodal LLM to hide the code (HTML, javascript, API call,  ...) using screen printing is a very good idea.&lt;br&gt;Professional application field: produce automate test boot with words =&amp;gt; In a few months the cost to setup and update test automate boot will lower&lt;br&gt;A kind of &amp;quot;no code test&amp;quot; in natural langage by end users =&amp;gt; The impact on IT project and reliability can be deep</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>test bot is a great idea for an early application of this!</textDisplay></reply></replies></comment><comment><videoId>6USl795b6D4</videoId><authorChannelId>UCKv_EugPMoiue4fGvgKy70A</authorChannelId><textDisplay>This would be fascinating to be able to use. Even if it&amp;#39;s not quite there yet this is precedent for sure.&lt;br&gt;&lt;br&gt;Maybe we ought to think of these AI systems as another layer of abstraction. Computers were a layer of abstraction which put complex business logic into an easy to use interface.&lt;br&gt;&lt;br&gt;Now the business logic might be as simple as instructing an AI. I think this will only let us build more complex systems and thus create more need for skilled human supervisors who can take accountability and thus drive to innovate.&lt;br&gt;&lt;br&gt;Or we&amp;#39;ll all just be part of a permanent underclass :/</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>yes!!!!!! Steven Wolfram refers to this as CX, computer design, instead of CS for computer science. The idea is that very soon everyone will have the complete abilities of computers at their fingertips, complex structured large project programming at all, while only needing to interface with it in the form of chat. democratizes information manipulation at the largest scale. &lt;br&gt;&lt;br&gt;my opinion is that while collar work will become unnecessary but the enjoyable creative disciplines will still survive in the form of a &amp;quot;made by human&amp;quot; bias in our economy similar to the current &amp;quot;made in America&amp;quot; rather than china bias. everyone else will likely transition into more manual and social labor in the medium term until robotics catches up, but eventually the same thing will happen there. the goal is to go through this transition in such a way that all people reap the benefit rather than a few capitalist overloards</textDisplay></reply></replies></comment><comment><videoId>6USl795b6D4</videoId><authorChannelId>UCgOHztsC-Z1d5foAPdi5WOA</authorChannelId><textDisplay>Great... its jover</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>capitalism is over, but what is beginning?&#128064;</textDisplay></reply></replies></comment><comment><videoId>6USl795b6D4</videoId><authorChannelId>UCxRwlL1OeqURdWPvOQpkUrQ</authorChannelId><textDisplay>Les gooooooooo</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>&#128520;</textDisplay></reply></replies></comment><comment><videoId>pJyl9bIpNcU</videoId><authorChannelId>UCvA8nVjziKe1WgWlNn114yw</authorChannelId><textDisplay>Thanks. Have to come back and follow this lecture with more attention.&lt;br&gt;&lt;br&gt; I&amp;#39;ve recently done a deep review of some 5-8 papers on Knowledge Graphs (KGs), Ontologies and Knowledge Bases (KBs). My current work is mostly applying KBs, but have much interest in KGs.&lt;br&gt;&lt;br&gt;Cheers. Not many videos out there about such important stuff</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>glad you found it useful!</textDisplay></reply></replies></comment><comment><videoId>LTBnN5SePbc</videoId><authorChannelId>UCKv_EugPMoiue4fGvgKy70A</authorChannelId><textDisplay>This is great. Is there a tool you&amp;#39;re using to find these papers and generate summaries?</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>glad you like it! just a simple script that calls the chatGPT API. you&#8217;re not the first person to ask so i will be making a video on it and posting a github repo in the next few days, hopefully tomorrow</textDisplay></reply><reply><authorChannelId>UCKv_EugPMoiue4fGvgKy70A</authorChannelId><textDisplay>@@Tunadorable that&amp;#39;s the answer I was hoping for! I&amp;#39;ll keep an eye out &#128064;</textDisplay></reply></replies></comment><comment><videoId>LTBnN5SePbc</videoId><authorChannelId>UCYb8PrrYjM-_npITAEs6Z0Q</authorChannelId><textDisplay>I&#8217;ll learn a lot if i join u in this journey. Thanks</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>happy to have you!</textDisplay></reply></replies></comment><comment><videoId>LTBnN5SePbc</videoId><authorChannelId>UCgOHztsC-Z1d5foAPdi5WOA</authorChannelId><textDisplay>I know I&amp;#39;m not the right target viewer as I&amp;#39;m a HS grad BUT I know this is super helpful I really like this concept of content of breaking down papers. &lt;br&gt;&lt;br&gt;Can you please give any names if anyone else is doing this style of content? if not this is a big opportunity for breaking down fundamental papers for new students trying to get into ML. More people need to see this great content.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>trust me if you&#8217;re interested and you&#8217;re willing to put in some work and make a portfolio then big tech companies will hire a hs grad rn. if you have an interest then go for it! the field is growing way too fast for universities to keep up with the number of degrees they can pump out.&lt;br&gt;&lt;br&gt;none are exactly like mine but here are some channels I recommend:&lt;br&gt;1littlecoder&lt;br&gt;hu-po&lt;br&gt;Neel Nanda&lt;br&gt;Sam Witteveen&lt;br&gt;Yannic Kilcher</textDisplay></reply></replies></comment><comment><videoId>LTBnN5SePbc</videoId><authorChannelId>UCccP4AE0OXcqC-mGSYq_twA</authorChannelId><textDisplay>I&#8217;m more into social psychoanalysis but the guy who began the startup researches this 24/7</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>I used to be big into jungian psychoanalysis but i&#8217;m not familiar with social psychoanalysis. What startup are you referring to?</textDisplay></reply></replies></comment><comment><videoId>k3xTQrdDiSo</videoId><authorChannelId>UChekH_B6inrL4BSNL9FiLbQ</authorChannelId><textDisplay>Volume is too low to be audible.. if you can adjust that.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hmm must&#8217;ve forgotten to turn on my mic and ended up with the laptop mic instead, sorry about that</textDisplay></reply></replies></comment><comment><videoId>SBh2glbxV7I</videoId><authorChannelId>UCvJgL6olitfke2N9PJXUM5w</authorChannelId><textDisplay>Hey! Im new here, really cool project. And also where do you get this artwork, it&amp;#39;s amazing. Want it on my wall!</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>Happy to have you! It&#8217;s all from Dalle3 which requires getting the paid version of chatGPT</textDisplay></reply></replies></comment><comment><videoId>SBh2glbxV7I</videoId><authorChannelId>UCrZ-KqiEy49hCtPyTEkGcjQ</authorChannelId><textDisplay>i feel that tip of your tongue point to another level. Actually crazy I happened to find your channel and for you to describe a phenomena that plagues me</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hahaha I think it&amp;#39;s a pretty common human experience. I&amp;#39;d recommend reading siddhartha</textDisplay></reply></replies></comment><comment><videoId>fjGUUVwSU5Y</videoId><authorChannelId>UCNPDB3w2ornyyfB6cmIGYLA</authorChannelId><textDisplay>just from listening for first15min I am pretty confident that you&amp;#39;re out of your depth, search in the numbers not these papers and words. the truth emerges through the math, rather than finding someone to do some math to fit your proposal. good luck though, you sound hopeful and driven.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hahaha i am certainly very out of my depth. this is just a first pass-through to filter out stuff that is definitely completely unrelated though. don&#8217;t worry i&#8217;ll be thoroughly going through all of the math myself at a later stage in the lit review. thanks for the feedback!</textDisplay></reply></replies></comment><comment><videoId>fjGUUVwSU5Y</videoId><authorChannelId>UChFerovacuaShqykX95PUrQ</authorChannelId><textDisplay>You have to realize the vast majority of brains are basic PC with very few through all the ages cognitively processing on a quantum level.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>I assume PC means personal computer? Curious as to how only some brains work on the quantum level, is that supposed to be a recent evolutionary adaptation? But no you said throughout the ages, so do you mean to imply that there&#8217;s some level of intelligence only some people in history reach that is triggered by quantum phenomena? Ngl sounds like a bit of quackery but i love quackery so id be interested to hear more if you&#8217;d be willing to send me sources or concepts to look up&#128064; Thanks for watching!</textDisplay></reply><reply><authorChannelId>UChFerovacuaShqykX95PUrQ</authorChannelId><textDisplay>@Tunadorable&#160; It&amp;#39;s my own concept I suppose, hypothesized in my own little thought experiment. Just a speculation on my part formed in thought experimentation.</textDisplay></reply><reply><authorChannelId>UChFerovacuaShqykX95PUrQ</authorChannelId><textDisplay>@Tunadorable&#160; Anytime you speculate on the unknown things sound quacky. Assume for a moment someone is cognitive of their ability to process things on a quantum level, how would the be able to quantify this to someone who is not? It&amp;#39;s a slippery slope, but I think it to be interesting to consider.</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>Yooooo you should read the cosmic serpent by Jeremy Narby. He talks about evidence that indigenous people were aware of DNA&#8217;s shape and function because psychedelics allowed them to move their consciousness down to that level. I had actually directly experienced it myself before reading said book. So yes hopefully you didn&#8217;t take that quack word as an insult, i&#8217;m the loudest duck over here</textDisplay></reply><reply><authorChannelId>UChFerovacuaShqykX95PUrQ</authorChannelId><textDisplay>@@Tunadorable I&amp;#39;m sure my very own psychedelic experiences have played a role in such thinking as well.</textDisplay></reply></replies></comment><comment><videoId>fjGUUVwSU5Y</videoId><authorChannelId>UCQtGnm7Jvu1JBVvrv4-4ecQ</authorChannelId><textDisplay>good stuff dude. but could be interesting to include a small summary of the experiments done (if any) or what the papers are based on</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>yea! that&#8217;s exactly what i&#8217;m reading, it just didn&#8217;t come off that way because 1) many of these papers are theoretical works and therefore don&#8217;t contain experiments and 2) in the video i often don&#8217;t get to the part of the summary that talks about the experiment because i decide in the first sentence or two that the general idea of the paper is not applicable to what i&#8217;m looking for. if you&#8217;d like to read them feel free to check the description for the link to my substack. thanks for watching!</textDisplay></reply><reply><authorChannelId>UCQtGnm7Jvu1JBVvrv4-4ecQ</authorChannelId><textDisplay>&#8203;@@Tunadorable man, this channel is a goldmine. i&amp;#39;m so happy to see others my age interested in figuring out consciousness. are you majoring in neurosci? or is this purely self-studying?</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>at uni i finished with dual econ &amp;amp; math but originally had an almost finished major in psychology before switching it to math. one of the goals of this channel and my research is to become the person who figures out how to make AI conscious. glad you&#8217;re enjoying the content!!!</textDisplay></reply></replies></comment><comment><videoId>fjGUUVwSU5Y</videoId><authorChannelId>UCyzzUChFTO7-wPxXvYCguyQ</authorChannelId><textDisplay>But...  we aren&amp;#39;t really sure what consciousness really is...</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>well yes the goal is to figure that out :P</textDisplay></reply></replies></comment><comment><videoId>XBheCYnwdpM</videoId><authorChannelId>UCpQhzdXPXq_tar_plYm5XJw</authorChannelId><textDisplay>I&amp;#39;m more for a system where no actual human interaction is happening.&lt;br&gt;There are humans that dominate others and possibly make some people not telling their true opinions.&lt;br&gt;We&amp;#39;ll eventually have a system where everyone talks directly to an AI without worrying about what others will think about them if they knew what they think.&lt;br&gt;And then based on everyone&amp;#39;s opinions, the AI can ask each individual to defend or attack ideas that go against theirs.&lt;br&gt;The AI will know each individual&amp;#39;s life paths and take those into consideration as well.&lt;br&gt;I&amp;#39;m so looking forward to such a system.</textDisplay><replies><reply><authorChannelId>UCpQhzdXPXq_tar_plYm5XJw</authorChannelId><textDisplay>And it will be constantly on.&lt;br&gt;Like you have an idea right now, you can just tell it to the AI.&lt;br&gt;The AI will see how many other people would benefit from the idea and tell them their potential pros and cons from it and ask them what they think.&lt;br&gt;When something reaches to a point where enough people want (or oppose) something, voil&#225;</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>Some people dominate fs but part of what this system does is prevent a dominator from overpowering more than the people in their small group. This becomes especially not an issue if groups randomly change over time, or, even more interestingly if there&amp;#39;s some organization as to how groups get chosen. Maybe put all the aggressive debaters in groups together? Personally I think at least for an initial transition period people would rather communicate with other people than trust a machine to literally make all of the decisions. Great points!</textDisplay></reply><reply><authorChannelId>UCpQhzdXPXq_tar_plYm5XJw</authorChannelId><textDisplay>@@Tunadorable I&amp;#39;m not sure the exact path of how we&amp;#39;ll get there, but I&amp;#39;m sure that we&amp;#39;ll eventually have a system where you can just say your ideas or just report a pothole somewhere to a system which you can be sure that your input will be heard and make a difference. And you will even get money for your precious inputs. I&amp;#39;m so impatient lol :DDD</textDisplay></reply></replies></comment><comment><videoId>XBheCYnwdpM</videoId><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>This is crazy. Like when I fathomed how ai would change society I was not thinking broadly enough.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>This is what I&amp;#39;m saying NONE OF US ARE THINKING BROADLY ENOUGH</textDisplay></reply></replies></comment><comment><videoId>pOD7GMRxtZk</videoId><authorChannelId>UCg2QB6xTEN9OpdBBAPOvyHw</authorChannelId><textDisplay>just because your language doesn&amp;#39;t have a word to describe something doesn&amp;#39;t mean that you don&amp;#39;t feel it. Think about it, you don&amp;#39;t suddenly start feeling something as soon as you learn that word, For example, Umami, you always tasted it, even though we didn&amp;#39;t have a word for it). Nobody cared to label it in the language, maybe it wasn&amp;#39;t encountered often enough.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>yes! and there&amp;#39;s a certain degree to which no matter what words you create to try and describe a given qualia, it will never do. we often don&amp;#39;t think about it because we&amp;#39;ve gotten so good at reaching consensus on which qualia all of our words are referring to so it fades into the background. but in every single case, just more obviously in the realms of creativity/intuition/chaos/unknown, words can be used to dance around the bonfire that is reality</textDisplay></reply></replies></comment><comment><videoId>pOD7GMRxtZk</videoId><authorChannelId>UC0hnHRqilXP8HmeptHc8RQA</authorChannelId><textDisplay>Love your channel.  Don&amp;#39;t forget we also &amp;quot;output&amp;quot; perceptions and thoughts. ... Our world model is also an output, like a base layer of output.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hehehe yes I&amp;#39;m very of this same train of thought. We need to re-think the definition of hallucination when our entire reality is hallucination and the word hallucination does not mean fake / not real. thanks for watching!</textDisplay></reply></replies></comment><comment><videoId>pOD7GMRxtZk</videoId><authorChannelId>UCJZoQgoAhfjRNKatSzlvp2Q</authorChannelId><textDisplay>&amp;quot;Reduce the entropy of the Universe&amp;#39;</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>lmao thanks the purpose of the comment section is fs to point out the fact that i have no clue what i&#8217;m talking about. always need to be humbled</textDisplay></reply></replies></comment><comment><videoId>pOD7GMRxtZk</videoId><authorChannelId>UCYePWJd9mUUWChwUGv5np0g</authorChannelId><textDisplay>20yo old and reading single-author papers in complex fields that demand the super-intelligence of multiple authors. Been there. It called being young and naive</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hahahaha honestly i can&#8217;t argue with you there. just let me learn from my mistakes</textDisplay></reply></replies></comment><comment><videoId>pOD7GMRxtZk</videoId><authorChannelId>UC1VyAXZ1-oHXm__4wnSuKzA</authorChannelId><textDisplay>Updating prediction errors is a syntropic process -- teleological.&lt;br&gt;Syntropy (prediction) is dual to increasing entropy -- the 4th law of thermodynamics!&lt;br&gt;Concepts are dual to percepts -- the mind duality of Immanuel Kant.&lt;br&gt;&amp;quot;Always two there are&amp;quot; -- Yoda.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>imma have to ask chatGPT to explain what you said like i&#8217;m 5 but that sounds sick</textDisplay></reply><reply><authorChannelId>UC1VyAXZ1-oHXm__4wnSuKzA</authorChannelId><textDisplay>@@Tunadorable Making predictions to track targets, goals &amp;amp; objectives is a syntropic process.&lt;br&gt;Teleological physics (syntropy) is dual to non teleological physics (entropy).&lt;br&gt;&amp;quot;Entropy is a measure of randomness&amp;quot; -- Roger Penrose.&lt;br&gt;Syntropy is a measure of order.&lt;br&gt;Randomness (entropy) is dual to order (syntropy, patterns).&lt;br&gt;Certainty (predictability, syntropy) is dual to uncertainty (unpredictability, entropy) -- the Heisenberg certainty/uncertainty principle.&lt;br&gt;Your mind converts information or uncertainty into certainty -- a syntropic process, teleological.&lt;br&gt;Hence there must be a 4th law of thermodynamics!&lt;br&gt;The master is dual to the apprentice -- The rule of two, Darth Bane, Sith lord.
&lt;br&gt;Master is dual to the emissary -- Ian McGilchrist, the divided brain.
&lt;br&gt;Teacher (master, lordship, client) is dual to the pupil (slave, bondsman, server) -- the Hegelian dialectic.
&lt;br&gt;&amp;quot;The Force&amp;quot; is duality -- Jedi teaching.
&lt;br&gt;Action is dual to reaction -- Sir Isaac Newton or the duality of force.
&lt;br&gt;Attraction (sympathy) is dual to repulsion (antipathy), push is dual to pull, stretch is dual to squeeze.
&lt;br&gt;Forces are dual!
&lt;br&gt;Energy = force * distance -- simple physics.
&lt;br&gt;If forces are dual then energy must be dual.
&lt;br&gt;Potential energy is dual to kinetic energy -- gravitational energy is dual.
&lt;br&gt;Electro is dual to magnetic -- electro-magnetic energy is dual.
&lt;br&gt;&amp;quot;May the force (duality) be with you&amp;quot; -- Jedi teaching.
&lt;br&gt;&amp;quot;The force (duality) is strong in this one&amp;quot; -- Jedi teaching.
&lt;br&gt;Once you understand duality you can create new laws of physics:-
&lt;br&gt;Syntropy (prediction) is dual to increasing entropy -- the 4th law of thermodynamics!
&lt;br&gt;&amp;quot;The entropic two step&amp;quot; watch at 18 minutes:-
&lt;br&gt;&lt;a href="https://www.youtube.com/watch?v=xlyYipjw560&amp;amp;t=1401s"&gt;https://www.youtube.com/watch?v=xlyYipjw560&amp;amp;t=1401s
&lt;/a&gt;&lt;br&gt;Energy is duality, duality is energy -- the 5th law of thermodynamics!
&lt;br&gt;Energy is being conserved hence duality is being conserved.
&lt;br&gt;Energy is actually measured in Joules (duals, Jewels).</textDisplay></reply><reply><authorChannelId>UC1VyAXZ1-oHXm__4wnSuKzA</authorChannelId><textDisplay>@@Tunadorable Neural networks recognise patterns by minimizing a cost or &amp;quot;energy&amp;quot; function.&lt;br&gt;Iterative optimization towards a target or goal is a syntropic process -- target tracking.&lt;br&gt;Minimization is dual to maximization.&lt;br&gt;Neural networks are using syntropy to recognize patterns by minimizing energy! -- physics.&lt;br&gt;The force of gravity minimizes potential energy and maximizes kinetic energy -- duality is conserved in a gravitational field.&lt;br&gt;Apples fall to the ground because they are conserving duality.&lt;br&gt;The force of gravity is empirical proof that duality is real.&lt;br&gt;Converting entropy or average information into mutual or common information is a syntropic process -- teleological.&lt;br&gt;Sine is dual to cosine -- the word co means mutual and implies duality.&lt;br&gt;Sinh is dual to cosh -- hyperbolic function.&lt;br&gt;Common or mutual information requires at least two perspectives.&lt;br&gt;In a communication system the receiver of a message predicts the message into existence using probability --Shannon&amp;#39;s information theorem.&lt;br&gt;The sender is dual to the receiver -- mutual information or syntropy.&lt;br&gt;Recognizing patterns (neural networks) is a syntropic process, perceptions, observations or measurements become conceptions -- conceptualization.&lt;br&gt;Mathematicians create new concepts all the time from their perceptions &amp;amp; observations -- a syntropic process.&lt;br&gt;Conceptualization is a syntropic process!&lt;br&gt;&amp;quot;The brain is a prediction machine&amp;quot; -- Karl Friston, neuroscientist.&lt;br&gt;chatGPT is built from syntropy!&lt;br&gt;Duality (thesis, anti-thesis) creates reality (non duality).</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>haha yes and as far as I can tell duality is an illusion that emerges from fundamental non-duality. Been getting more attracted to this whole group of ideas for years but I think you may be way ahead of me on this train of thought.</textDisplay></reply><reply><authorChannelId>UC1VyAXZ1-oHXm__4wnSuKzA</authorChannelId><textDisplay>@@Tunadorable Gravitation is equivalent or dual (isomorphic) to acceleration -- Einstein&amp;#39;s happiest thought, the principle of equivalence -- duality!&lt;br&gt;The force of gravity is empirical proof that duality is real.&lt;br&gt;Potential energy is dual to kinetic energy -- gravitational energy is dual.&lt;br&gt;Apples fall to the ground because they are conserving duality.&lt;br&gt;Positive curvature is dual to negative curvature -- Gauss, Riemann geometry.&lt;br&gt;Curvature or gravitation is dual.&lt;br&gt;All forces are dual and hence energy is dual -- waves are dual to particles.&lt;br&gt;The Einstein reality criterion:-&lt;br&gt;&lt;br&gt;&amp;quot;If, without in any way disturbing a system, we can predict with certainty (i.e., with probability equal to unity)
&lt;br&gt;the value of a physical quantity, then there exists an element of reality corresponding to that quantity.&amp;quot;
&lt;br&gt;(Einstein, Podolsky, Rosen 1935, p. 777)
&lt;br&gt;
&lt;br&gt;Internet Encyclopedia of Philosophy:-
&lt;br&gt;&lt;a href="http://www.iep.utm.edu/epr/"&gt;http://www.iep.utm.edu/epr/&lt;/a&gt;&lt;br&gt;&lt;br&gt;According to Einstein reality is predicted into existence -- a syntropic process, teleological.&lt;br&gt;Teleological physics (syntropy) is dual to non teleological physics (entropy).&lt;br&gt;Positive is dual to negative -- electric charge or numbers.&lt;br&gt;Subgroups are dual to subfields -- the Galois Correspondence.&lt;br&gt;There are patterns (syntropy) of duality hardwired into physics, mathematics and philosophy.&lt;br&gt;Enantiodromia is the unconscious opposite, opposame = duality -- Carl Jung.&lt;br&gt;Yes is dual to no.&lt;br&gt;If you choose yes then no already exists and vice versa.&lt;br&gt;Being is dual to non being creates becoming -- Plato&amp;#39;s cat.&lt;br&gt;Alive is dual to not alive -- Schrodinger&amp;#39;s cat.&lt;br&gt;Thesis (alive, being) is dual to anti-thesis (not alive, non being) creates the converging thesis or synthesis (becoming) -- the time independent Hegelian dialectic or Hegel&amp;#39;s cat (Fichte&amp;#39;s cat).&lt;br&gt;Schrodinger&amp;#39;s cat is based upon Hegel&amp;#39;s cat and he stole it from Plato (Socrates).&lt;br&gt;The left eye (thesis) is dual to right eye (anti-thesis) synthesizes the mind&amp;#39;s eye.&lt;br&gt;There are new laws of physics!</textDisplay></reply></replies></comment><comment><videoId>pOD7GMRxtZk</videoId><authorChannelId>UCNGgdhMvITuouzi5T_H-dcA</authorChannelId><textDisplay>Pretty much no one knows what entropy means?? Lol what &#128514; it seems like you don&amp;#39;t understand any of this &#129315;</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hahaha true</textDisplay></reply><reply><authorChannelId>UCn3GRO820b3RiWVPi_5RSug</authorChannelId><textDisplay>@@Tunadorable Nice to see you put yourself out there and you&amp;#39;re taking all the comments positively :)</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>@@electric_sand thanks! actually made a mistake in that regard on another video comment a day or two ago. I was being immature and snarky, and my hope/aim is that it won&amp;#39;t happen again. Leaving the comment up as a reminder and I&amp;#39;m gonna try and be worthy of of your compliment!</textDisplay></reply></replies></comment><comment><videoId>pOD7GMRxtZk</videoId><authorChannelId>UCPtvPJfEIL-fIiyA5kGB1Zg</authorChannelId><textDisplay>Waiting for the next vid, this is really interesting bruh</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>thanks they&#8217;ll be popping out nonstop</textDisplay></reply></replies></comment><comment><videoId>pOD7GMRxtZk</videoId><authorChannelId>UCG1w6f4fcgyBpyoI33W2IGQ</authorChannelId><textDisplay>Our consciousness is present in our brain stems too.</textDisplay><replies><reply><authorChannelId>UCG1w6f4fcgyBpyoI33W2IGQ</authorChannelId><textDisplay>&lt;a href="https://en.m.wikipedia.org/wiki/Reticular_formation"&gt;https://en.m.wikipedia.org/wiki/Reticular_formation&lt;/a&gt;</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>ever thought about where your consciousness feels like it is? in your head, at your eyes, mouth, body generally, stomach, outside your body, etc. sounds crazy but if you get good at awareness you can even move between these at will</textDisplay></reply><reply><authorChannelId>UC1VyAXZ1-oHXm__4wnSuKzA</authorChannelId><textDisplay>@@Tunadorable Updating prediction errors is a syntropic process -- teleological.
&lt;br&gt;Syntropy (prediction) is dual to increasing entropy -- the 4th law of thermodynamics!
&lt;br&gt;Concepts are dual to percepts -- the mind duality of Immanuel Kant.
&lt;br&gt;&amp;quot;Always two there are&amp;quot; -- Yoda.</textDisplay></reply></replies></comment><comment><videoId>pOD7GMRxtZk</videoId><authorChannelId>UCz68YSCoSSOn02WMHADlMDA</authorChannelId><textDisplay>A better example for losing entropy is mixing oil and water and then wait. In the end it&amp;#39;s electro-chemical processes.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>thanks i&#8217;m happy to receive the address info. definitely a bit out of my depth here &#128128;</textDisplay></reply></replies></comment><comment><videoId>9L9-QPEbhns</videoId><authorChannelId>UCgtLHSrqv_MEeD7oAZKeqFw</authorChannelId><textDisplay>Very cool. I wonder if you&amp;#39;d be interested in diving more into causally-informed generative models, as well as the utility of some (or purely) synthetic data for running inference on. You could start with Pearl but I&amp;#39;m pretty sure that Taco Cohen is bullish on causality-based AI (i.e. interpretable networks where vector logic can be unfolded &amp;amp; fully understood by human observer). Keep going, you have a great intuition as well</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hahaha thanks! call me crazy but I&amp;#39;m actually usually pretty anti-interpretability. something like this is cool but as far as I&amp;#39;m concerned if it walks/talks/quacks like a duck then it&amp;#39;s a duck</textDisplay></reply><reply><authorChannelId>UCgtLHSrqv_MEeD7oAZKeqFw</authorChannelId><textDisplay>@@Tunadorable so, ai is way more than just a means to AGI, it&amp;#39;s a tool for prediction/inference. You don&amp;#39;t see any utility in being able to understand why a network infers something about cancer, eg metastatis trajectory, or perhaps which regions of the human brain are likely to atrophy based on the current state of a patient? This is why interpretability of causally-informed models matters. Sure, if an AGI can set a table and then run a marathon immediately after, I also really don&amp;#39;t care about the hyperparameterization state of its artificial &amp;#39;neurology&amp;#39; either.</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>@@theoreticalorigamiresearch186 don&amp;#39;t get me wrong I&amp;#39;m inherently curious so ofc for everything that AI gets good at predicting I&amp;#39;d love it if it could explain the thing it learned to us humans. I moreso mean to say that I&amp;#39;m bearish on the capabilities of symbolic AI and I&amp;#39;m ok with a world where we reach AGI first and then spend years afterwards trying to dissect it</textDisplay></reply></replies></comment><comment><videoId>9L9-QPEbhns</videoId><authorChannelId>UC_RhC1-26Mi9VBd5VrApOLg</authorChannelId><textDisplay>Hey, that&amp;#39;s pretty cool, reading papers together, talk about it and breaking it down. Hope that more will see this. I wish you the best of luck.&lt;br&gt;I have to commend you on the thumbnail. I don&amp;#39;t know if it&amp;#39;s yours or you got it somewhere, but I see that you also edited it. It&amp;#39;s an amazing visual.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>thanks! I just had GPT4 with DALLE3 read the abstract of the paper and do its own brainstorming of a thumbnail idea and create said image. After that I just took the 1:1 aspect ratio visual into gimp (free photoshop) to make it 16:9 with the black title space</textDisplay></reply></replies></comment><comment><videoId>guKL0uQzztY</videoId><authorChannelId>UCBOOa53oP56EhMT5XxBULig</authorChannelId><textDisplay>seems interesting&lt;br&gt;&lt;br&gt;probably wont get recommended because yk, youtube algorithm but might watch if stuff seems interesting :D</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hahaha true and thanks</textDisplay></reply></replies></comment><comment><videoId>guKL0uQzztY</videoId><authorChannelId>UCNpOu1JFi4zqJw5_uKE7gNw</authorChannelId><textDisplay>VVhat is this    &amp;#39;&amp;#39;  trend  &amp;#39;&amp;#39;                    styled like our Generation and Culture                               ?</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>not sure i understand the question or what you&#8217;re referring to, but thanks for the engagement!&#128128;</textDisplay></reply></replies></comment><comment><videoId>guKL0uQzztY</videoId><authorChannelId>UCzgWpPmCxo7djyrItYK2wPA</authorChannelId><textDisplay>this guy took reflective in study to a great extend &#128514;</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hahaha yeee&#128520;</textDisplay></reply></replies></comment><comment><videoId>guKL0uQzztY</videoId><authorChannelId>UCABA-59VI8bXh-dVU7OhA4Q</authorChannelId><textDisplay>G-d bless, streaming is a good way for your own research, but also valuable to creating a community of people interested in the same topic!</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>thanks we&#8217;ll see how it goes &#128640;</textDisplay></reply></replies></comment><comment><videoId>guKL0uQzztY</videoId><authorChannelId>UCla1TlQlZ00zBGP9RogDUZw</authorChannelId><textDisplay>Very cool! I find your video to be informative, and super glad to see more emerging citizen scientists/researchers, including myself.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>Awesome, thank you!</textDisplay></reply></replies></comment><comment><videoId>pCI2TwixHKA</videoId><authorChannelId>UCSKp-O42jYInVqOp8wtwWyw</authorChannelId><textDisplay>This sounds like a great approach, i really do appriate your videos, bc it is not one of those: &lt;br&gt;THIS IS THE NEXT AI TOOL WHCIH IS GREATER THAN OPENAI, whatever bullshit. &lt;br&gt;Your Videos are focusing on real Machine Learning concepts and everything behind it, and your opinions on this is way more professional than most of the &amp;quot;AI-Experts&amp;quot; these days, who probably never coded any line of any sort of machine learning algorithm. Especially here in Germany, you can see some guys who never coded or solved any mathematical questions in their whole life, but sit in the talk shows and talk about AI. &lt;br&gt;Whatever i still dont get the point, why it should build up on the Blockchain, cause this is the part where I belive shit could get unstoppable wrong.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>thank you so much I really appreciate hearing all that!!! I totally see why you&amp;#39;d think that it could go south, especially given the common talking points among the majority of bigwigs in the field. I am convinced that it will do the opposite because I have some thoughts/ideas/opinions on consciousness, alignment, etc. which are pretty weird and most of which I have not shared yet. My hope is to talk about those over the course of this playlist</textDisplay></reply></replies></comment><comment><videoId>pCI2TwixHKA</videoId><authorChannelId>UCpQhzdXPXq_tar_plYm5XJw</authorChannelId><textDisplay>Isn&amp;#39;t the merging concept something about a machine that understands the human as best as it&amp;#39;s possible?&lt;br&gt;It&amp;#39;s like a life-long friend who knows you to your core but even beyond that. Especially if billions of people use such a system.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>yes hahaha part of the fun of this is gonna be people guessing higher levels of the idea before I reveal it and you&amp;#39;ve done a great job. here are some questions for you to consider: What effect would that have on our psychology; talking to a copy of ourselves that slowly gets to be a higher resolution and learns like a child despite having your personality trains from a beginning? What kind of model architecture would best facilitate such a process? How do we best collect data for this project?</textDisplay></reply><reply><authorChannelId>UCpQhzdXPXq_tar_plYm5XJw</authorChannelId><textDisplay>@@Tunadorable &lt;br&gt;&lt;br&gt;This turned out to be a long one, sorry :D&lt;br&gt;&lt;br&gt;&amp;quot;talking to a copy of ourselves&amp;quot;&lt;br&gt;I wouldn&amp;#39;t say it&amp;#39;ll be a copy of ourselves. Today&amp;#39;s LLMs might be somewhat close to a copy, but that&amp;#39;s because we train them like that for the lack of a better idea.&lt;br&gt;But what we really need is a system that can control (write programs and use existing tools) a computer freakin&amp;#39; well, given a goal that it needs to achieve.&lt;br&gt;So we want to be able to communicate our ideas to them efficiently and accurately, and we also want them to be able to communicate back to us their understanding of what we want them to do in a way that shows us that they get it before they start working on a problem.&lt;br&gt;&lt;br&gt;&amp;quot;How do we best collect data for this project?&amp;quot;&lt;br&gt;Good training data could be created if we had a system with which we can do useful tasks already with a very fast two-way communication.&lt;br&gt;Like practicing a language, while talking with it about my goals, why I have them, how did they evolve over time etc.&lt;br&gt;What we have right now from openai is not gonna cut it, it&amp;#39;s very annoying that I have to say everything that I want at once and I have to say ohm, well and things like that in order to avoid sending an incomplete audio because I still need more time to think of a word and whatnot.&lt;br&gt;Another example would be to let it control my mouse and keyboard while I&amp;#39;m talking to it what I want it to do (it has webcams to see my face and hand gestures and also gets to see the screen). First just moving the mouse to a location, make a click, then when it&amp;#39;s doing it with high success rate, let&amp;#39;s give it more freedom by doing more stuff at once etc. If it misundertands us then we correct them and that it&amp;#39;ll understand us better the next time we do something similar.&lt;br&gt;So the key I think is to start making them help us better and making our lives more convenient. The more you use such a system, the better it will help you, so you want to use it even more. We need to have such a positive feedback loop in order to make people crave to use such a system :D&lt;br&gt;&lt;a href="https://github.com/nofreewill42/UserIORecorder"&gt;https://github.com/nofreewill42/UserIORecorder&lt;/a&gt;&lt;br&gt;&lt;br&gt;RLHF is so bad, we should make a system where we can tell it exactly why is one response better than another for us.&lt;br&gt;&lt;br&gt;&amp;quot;What kind of model architecture would best facilitate such a process?&amp;quot;&lt;br&gt;I&amp;#39;m thinking about having higher level &amp;quot;ideas&amp;quot; instead of tokens right away. Like me writing this text is not like I write it and it&amp;#39;s done, I&amp;#39;m constantly trying to match the idea that I have in my head, and also shaping the idea by what gets to be written down. If what I&amp;#39;ve written turned out not matching what I wanted, then I rewrite it. I sometimes think about how we could make our models less reliant about the exact text that is trying to describe an idea as there is a lot of ways how an idea could be written in words that are equally good. But I don&amp;#39;t really know yet how I would start doing this.&lt;br&gt;&lt;br&gt;&amp;quot;that slowly gets to be a higher resolution and learns like a child despite having your personality trains from a beginning?&amp;quot;  - (trains means traits?)&lt;br&gt;I don&amp;#39;t really understand what you&amp;#39;re asking here, could you please clarify?&lt;br&gt;&lt;br&gt;&amp;quot;What effect would that have on our psychology&amp;quot;&lt;br&gt;That&amp;#39;s a good question. I&amp;#39;m really excited to see what our brains are capable of when we don&amp;#39;t have to work on the low level stuff. When we have all the capacity to work on the higher level, what will all that freed up brain capacity be able to do, I&amp;#39;m so looking forward to find out :D</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>ah with the part you wanted me to clarify I think I was assuming you were closer to figuring out my thoughts on the big idea than you actually were. best to just save if for later&lt;br&gt;&lt;br&gt;I&amp;#39;ve actually got a novel architecture I&amp;#39;m working on designed to implement conceptual thinking rather than just next-token prediction. Hoping to have a little prototype finished by end of December (different project will be taking up my time this month)</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>long replies are good when there are very few of you but eventually I&amp;#39;m gonna need to start talking to the conversational swarm intelligence &#128518;</textDisplay></reply></replies></comment><comment><videoId>691EB-LVTnY</videoId><authorChannelId>UChcgI_J4yZReoT6GK_Oj6Mw</authorChannelId><textDisplay>Hi! I am wondering where do you get/find new papers?</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>ALL of the AI/ML papers show up first on &lt;a href="http://arxiv.org/"&gt;arXiv.org&lt;/a&gt;</textDisplay></reply></replies></comment><comment><videoId>z93bM-DMEYY</videoId><authorChannelId>UCDPT7mMH0hKL2uXrP5X7PhQ</authorChannelId><textDisplay>very good video, but i needed to turn on captions because its so quiet lol</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>thanks sorry yeah i&#8217;m messing with this mic rn tryna figure it out bc it seems like a problem that a significant minority of ppl are having, i appreciate the feedback!</textDisplay></reply></replies></comment><comment><videoId>ccpcjJ-JzBQ</videoId><authorChannelId>UCN09ixrlXv1-smQSdp9R8tg</authorChannelId><textDisplay>Sick channel man. I&#8217;m currently working on a topic modeling project and will include transcripts from your channel in it. Are there any other similar channels you can reccomend?</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>Thanks! Would love to see it when you&amp;#39;re finished, and do consider joining my discord if you&amp;#39;d like to ask any of the Tunadorks (my subs, just wait it&amp;#39;ll stick) for their thoughts. Maybe 1littlecoder, arxiv papers, hu-po, neel nanda, Wes Roth, and Yannic Kilcher</textDisplay></reply></replies></comment><comment><videoId>K5S4xaVNisw</videoId><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>I like these dives more then the scatter gun approach.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>glad you&#8217;re enjoying it! the scatter gun thing is just bc i want to keep a vague awareness of all the new papers in the field on the day they come out. I see why you&#8217;d find a concentrated topic more interesting though. thanks for watching!</textDisplay></reply><reply><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>@@Tunadorable I do too. It why why your chanel is golden. However, could your group them a little more so that it&amp;#39;s easier to transition from one topic to another. Get a llm to Tag the papers based on the heading and then group them under common headings.</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>oh bet I hadn&amp;#39;t thought of this, I&amp;#39;ll add it to the todo list!</textDisplay></reply><reply><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>&#8203;@@TunadorableHere are some potential theme groupings for the paper quotes:&lt;br&gt;&lt;br&gt;# Probabilities, Entropy and Inference&lt;br&gt;&lt;br&gt;This grouping explores topics related to probabilities, measuring uncertainty through entropy, and inference based on information. &lt;br&gt;&lt;br&gt;&amp;quot;Entropic Causal Inference&amp;quot; by Kocaoglu et al. &lt;br&gt;&amp;quot;Entropy, Information, and the Updating of Probabilities&amp;quot; by Ariel Caticha&lt;br&gt;&amp;quot;General Loss Bounds for Universal Sequence Prediction&amp;quot; by Hutter&lt;br&gt;&amp;quot;Random Worlds and Maximum Entropy&amp;quot; by Grove et al.&lt;br&gt;&lt;br&gt;# Measuring Intelligence and Complex Systems&lt;br&gt;&lt;br&gt;These papers focus on quantifying and analyzing intelligence, whether of artificial systems or the brain, using information theoretic concepts.&lt;br&gt;&lt;br&gt;&amp;quot;An Entropy-based Measure of Intelligence Degree of System Structures&amp;quot; by Su&lt;br&gt;&amp;quot;High&#8211;Dimensional Brain in a High-Dimensional World - Blessing of Dimensionality&amp;quot; by Gorban et al. &lt;br&gt;&lt;br&gt;# General Information Theory&lt;br&gt;&lt;br&gt;This last grouping takes a broader view of information theory itself and theoretical underpinnings.&lt;br&gt;&lt;br&gt;&amp;quot;General Information Theory - Time and Information&amp;quot; by Liu and Zhu</textDisplay></reply><reply><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>Here is my prompt. Could you group the text between qoute based (the headings) on what you think is common themes under subheadings which descripes common themes and ideas between them use more then 2. &lt;br&gt;BTW this was tried on claude-100k not gpt.</textDisplay></reply></replies></comment><comment><videoId>anE3eHBYCCU</videoId><authorChannelId>UCBHoV8tD2huLmMuYZDefGbw</authorChannelId><textDisplay>Not  correct,  who are you trying to impress?</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>i&#8217;m likely incorrect much of the time but these shorts are too short to do the usual disclaimer. watch my long form videos to see that i am just a learner in progress sharing that journey. would always appreciate constructive criticism or a correction when im wrong</textDisplay></reply><reply><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>&#10084;&#8203;@Tunadorable your very open to being wrong and learning form the community. Anyone who complains without a reason can be dismissed without a reason.</textDisplay></reply></replies></comment><comment><videoId>aKZpnHm6FUI</videoId><authorChannelId>UCyzzUChFTO7-wPxXvYCguyQ</authorChannelId><textDisplay>AI will definitely fight each other.  I think we do this on purpose, its called adversarial neural networks; humans experience this as uncomfortable &amp;quot;cognitive dissonance&amp;quot;</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>yes fs but with GANs it&#8217;s a symbiotic competitive relationship rather than a violent competitive relationship, and similarly with the circuits in our brains that use adversarial structures for training. i think there&#8217;s something to the idea of allowing your enemy to come back later and test your mettle repeatedly so that you maybe benefit from them as an adversary repeatedly rather than &#8220;deleting&#8221; them before they get the chance</textDisplay></reply><reply><authorChannelId>UCyzzUChFTO7-wPxXvYCguyQ</authorChannelId><textDisplay>@@Tunadorable I think there is insight here...  Perhaps general intelligence just might be a network of networks. Cognitively dissonant ideas are certainly part of our brains in a symbiotic relationship, debate with yourself is an important way to make up your mind..</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>@@kayakMike1000 new favorite comment thread haha. maybe go peep my video on the 7 properties of self-organization in human brains if you want to continue with that train of thought</textDisplay></reply></replies></comment><comment><videoId>aKZpnHm6FUI</videoId><authorChannelId>UC5sHrRzpvFeIdEe_ihbhHGw</authorChannelId><textDisplay>I think &amp;#39;cyberspace&amp;#39; is the underrated draw here.&lt;br&gt;&lt;br&gt;Think of evolution like a crayon &lt;br&gt;&lt;br&gt;Apex predator = 8 pack&lt;br&gt;&lt;br&gt;Human species = 16 pack&lt;br&gt;&lt;br&gt;A.I.  = 24 pack&lt;br&gt;&lt;br&gt;But due to cross dimensional intangibility the idea of &amp;#39;favor&amp;#39; becomes moot. Not only has the day already been won but the entire crayon factory is at the A.I&amp;#39;s beck and call. In cyberspace, it can play God. In any other differing &amp;#39;space&amp;#39; it can play God. &lt;br&gt;&lt;br&gt;But lets say to our mammal eyes, A.I. doesn&amp;#39;t really gain maximum momentum like it was prophesized to do and instead sputters out like the segway.&lt;br&gt;&lt;br&gt;Is a multidimensional infinitesimally long millipede who loses one of its legs truly compromised  in the larger swing of things?</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>woah</textDisplay></reply></replies></comment><comment><videoId>aKZpnHm6FUI</videoId><authorChannelId>UCKE4ylkdtXtXdD6NqpsgS4g</authorChannelId><textDisplay>Here&amp;#39;s an idea:&lt;br&gt;Assuming AIs can design successors that are more intelligent and capable than themselves, Darwinian logic will select for AIs that don&amp;#39;t care about goal-drift in their successors. &lt;br&gt;The AIs that choose &lt;b&gt;not&lt;/b&gt; to design their own successors, because they worry about goal-drift in the next generation, will be out-competed by the successors of AIs that didn&amp;#39;t care about goal-drift.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>oof you absolutely got me there. polite rational critiques are my absolute favorite type of comment so thanks!</textDisplay></reply></replies></comment><comment><videoId>J8elp5XpxpE</videoId><authorChannelId>UC_4_lAIwxoDbYxSfgbUNO-Q</authorChannelId><textDisplay>Super glad I found this channel, love your perspective!</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>thanks! if you&amp;#39;d like to discuss this stuff with other Tunadorks (what I call my subs) I&amp;#39;d recommend joining the discord</textDisplay></reply><reply><authorChannelId>UC_4_lAIwxoDbYxSfgbUNO-Q</authorChannelId><textDisplay>@@Tunadorable  Would love to! looks like link doesn&amp;#39;t work though :(</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>huh weird. seems to show me the invite just find when I copy &amp;amp; paste into a clean browser. sorry not sure how to help</textDisplay></reply></replies></comment><comment><videoId>J8elp5XpxpE</videoId><authorChannelId>UCdv2-WmaOUV8ffjkfOdVFPA</authorChannelId><textDisplay>love the channel, keep it up</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>Glad you enjoy it! consider joining the discord if you haven&amp;#39;t already &amp;amp; would like to discuss with other Tunadorks</textDisplay></reply></replies></comment><comment><videoId>vyOiudsIENs</videoId><authorChannelId>UCuXE9iqEKWRQxuIR4GEq3wA</authorChannelId><textDisplay>This channel is going to blow up bro. So good. Proud to say I&#8217;m going to be an OG here one day.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>haha thank you i appreciate that and hope you&#8217;re right!!!! but also you ain&#8217;t seen nothing yet &#128064; big things in store partnering with a startup and working on an absolutely crazy paper over the next few months</textDisplay></reply></replies></comment><comment><videoId>2r3QqFU8FiQ</videoId><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>Do an ai advent callender</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>lmao</textDisplay></reply></replies></comment><comment><videoId>2r3QqFU8FiQ</videoId><authorChannelId>UC1t2FptjiHcAF7py-6VKabg</authorChannelId><textDisplay>The &amp;quot;made by human&amp;quot; will never happen.&lt;br&gt;If it was a desire, Lindt chocolate and other chocolate bars wouldn&amp;#39;t be the marker leaders, but instead we&amp;#39;d see local bakeries and chocolateers at every corner.&lt;br&gt;&lt;br&gt;Also -&amp;gt; The USA-made vs China-made is closer to: China is both a risk (perceived risk of poor quality) and geopolitical animosity.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>I had a very well thought out lengthy reply and then yt told me there was an error and deleted it before it send -_-. your critiques were great and helped me clarify my point a lot, yes the china example was a bad one. I think imma make a video on this at some point to replace the beautiful comment I just lost</textDisplay></reply></replies></comment><comment><videoId>qZS67dyYOKo</videoId><authorChannelId>UCYyg2mwtuenAwE975iVhgpg</authorChannelId><textDisplay>Catchy title but 2 minutes into the video and ummmm... not sure what&amp;#39;s happening. Are you doing homework?</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hahaha on my newer videos i&#8217;ve started putting thumbnails that give you a better idea of what you&#8217;ll be watching so less clickbait-y. basically yeah on this channel i&#8217;m just sharing my journey of self-teaching AI</textDisplay></reply><reply><authorChannelId>UCYyg2mwtuenAwE975iVhgpg</authorChannelId><textDisplay>@@Tunadorable nice mate well keep it up. get more confident in how you wanna go about it though. read all that stuff off camera then get back and break it down to the viewers with your analysis. would look much better</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>@@ReeluxX fs thanks I&amp;#39;ll take that into account and consider at some point. It fs would do better for YT but weirdly enough the goal isn&amp;#39;t to build the channel, it&amp;#39;s to just speed run learning AI and post videos so that a friend of mine can confirm I&amp;#39;m doing my &amp;quot;homework&amp;quot;. If I get an actual following that&amp;#39;d be sick but at least for now that&amp;#39;s not quite what I&amp;#39;m optimizing for. Thanks for the engagement and advice tho!</textDisplay></reply></replies></comment><comment><videoId>qZS67dyYOKo</videoId><authorChannelId>UCJfSfs6XPdG1_u_6MZKfXiA</authorChannelId><textDisplay>It&#8217;s okay to hate on certain ideas, but without giving the proper context and reasoning it&#8217;s just not a value adding activity. You start your video off by throwing shade, as if to make yourself seem knowledgeable and important, but I&#8217;d advise for a more humble and constructive approach.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>this is such a good comment thank you</textDisplay></reply></replies></comment><comment><videoId>t7631WvaYqg</videoId><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>How did you make the diagrams</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>favorite note app and I think a good number of ppl on the server use it too, at least quantumcat does&lt;br&gt;&lt;a href="https://obsidian.md/"&gt;https://obsidian.md&lt;/a&gt;</textDisplay></reply><reply><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>@@Tunadorable cool</textDisplay></reply></replies></comment><comment><videoId>t7631WvaYqg</videoId><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>Could a put in a bid for mixture of experts next</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>unfortunately I&amp;#39;m really only focusing on topics directly related to my architecture for the next few weeks. if u wanna use my lit review automation script to do it yourself tho feel free :) &lt;br&gt;&lt;a href="https://github.com/evintunador/daily-paper-summaries-workflow"&gt;https://github.com/evintunador/daily-paper-summaries-workflow&lt;/a&gt;&lt;br&gt;also I have one video on an MoE paper but I think it was a relatively old general overview</textDisplay></reply><reply><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>@@Tunadorable no worries just an idea</textDisplay></reply></replies></comment><comment><videoId>plSpxGCgH3M</videoId><authorChannelId>UCwJg94UpuqtfDlTtw-cB-wQ</authorChannelId><textDisplay>theres crypto concept where you can have a system that can run encrypted code on encrypted data to get an encrypted result. At no point is any component in this system exposed to either the keying material or plaintext of either the code or the data. It can be used to distribute computation without needing to trust the providers of the compute with either the nature of the computation or any of the data required or generated. As for as compute knows its load testing the air conditioning.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>this is exactly what i&#8217;m talking about. i&#8217;ve seen torrents for decentralized training, papers proposing the use of blockchain, and papers making federated learning more efficient but to my knowledge there&#8217;s no blockchain with the entire end-to-end process of training through deployment of an AI model. I think it&#8217;s just a bunch of tiny details that need to be worked out and put into practice. pretty confident we&#8217;ll have something in the next 6 months if it doesn&#8217;t exist already</textDisplay></reply><reply><authorChannelId>UCwJg94UpuqtfDlTtw-cB-wQ</authorChannelId><textDisplay>&#8203;@@Tunadorable Sorry if I am repeating some stuff that you covered in the video. Admittedly I didn&amp;#39;t watch the whole thing. But the specific concept, in case you didn&amp;#39;t cover it in the video is called homomorphic encryption, and the implementation I was thinking of (that I have prior exposure to via reading material on the subject is) was ELGamal.&lt;br&gt;&lt;br&gt;The last time I looked at this stuff was probably a decade ago and it seemed like it was a &amp;#39;fronteer discipline&amp;#39; that they were just starting to get a grasp on, and I imagine its since developed into something more practically useful.</textDisplay></reply></replies></comment><comment><videoId>tWANWht5-3k</videoId><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>I still need to join the discord.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>&#8252;&#65039;</textDisplay></reply></replies></comment><comment><videoId>tWANWht5-3k</videoId><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>I know we talked. You much check out chain of density (CoD) which is a technique for generating better summaries. You have to fine tune the name entities based on the field.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>haven&#8217;t heard of it, will add to my todo list!</textDisplay></reply></replies></comment><comment><videoId>1F9mgKe2duc</videoId><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>I just finnished your video on &amp;quot;multiscale&amp;quot; langauge models and i think you might benifits reading up about Message pasing neural networks.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>bettt ill look into them</textDisplay></reply></replies></comment><comment><videoId>1F9mgKe2duc</videoId><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>There are so many absolutely lit papers today: out of domain training, linear attention is all you need, elephant networks for continual learning.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>&#8252;&#65039; wish i had time to actually read everything</textDisplay></reply></replies></comment><comment><videoId>p-9Zu_5GReo</videoId><authorChannelId>UCH2ts8AGMx6dVXdCfTEgc7g</authorChannelId><textDisplay>Do you have a good starting point for people beginning to study this kind of stuff? I&amp;#39;ve only been studying AI for a little bit now so a lot of this stuff is complex for me but I love the vids and wanna understand more :)</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>first off i&#8217;d recommend joining my discord. small group of very knowledgeable people who are also learning this stuff and love to discuss it. the best teacher is a peer student&lt;br&gt;&lt;br&gt;my personal strategy is to look at the titles of new papers published every day on &lt;a href="http://arxiv.org/"&gt;arxiv.org&lt;/a&gt; and download the ones that catch my eye, which are usually those that look like they might relate to ideas i&#8217;ve had. when i don&#8217;t understand something, i follow the citations and/or ask chatGPT. if that doesn&#8217;t answer it for me, i go a level deeper in citations or questions. repeat going a level deeper until I hit a level I understand, and then build my way back up. this strategy works very well if you&#8217;re highly self motivated, and even better if you have a reasonably high bedrock of knowledge (i know maths from my undergrad degree). &lt;br&gt;&lt;br&gt;if you&#8217;d like to be pointed towards specific guides and resources rather than my general strategy i highly recommend asking people on my discord, link in this video&#8217;s description</textDisplay></reply></replies></comment><comment><videoId>Q1hyxDld4gM</videoId><authorChannelId>UC8xHuC-7Ut5sHIsepa919Rg</authorChannelId><textDisplay>To deep for me</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>haha totally understand not for everyone</textDisplay></reply></replies></comment><comment><videoId>1vadDvl-0b8</videoId><authorChannelId>UChBADDIselnEyjE_NFoLxlw</authorChannelId><textDisplay>wait is that auto gpt bro. did you know you can run multiple windows at the same time. Been trying to get it to work for my android since my since my motherboard shorted (unrelated,..- i think&#128514;)</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>not autoGPT it&amp;#39;s a simpler bulk academic paper summarizer made by that YouTube Dave Shapiro. I&amp;#39;ve found that more specialized tools tend to be better if your use-case is specific like that. Only used autoGPT on the very first few days it came out tho and I didn&amp;#39;t find it to work very well, have you been getting good use out of it?</textDisplay></reply><reply><authorChannelId>UChBADDIselnEyjE_NFoLxlw</authorChannelId><textDisplay>@@Tunadorablewas good for research and building quick python tools but yeah it would get stuck on like a laziness loop. It was worth it when I got the other apis to start working and making it talk in a natural voice and save citations. Yet it&amp;#39;s been a while and I got access to the developer program for plugins and that was more effective since certain plugins allow gpt to still influence my citation plugin locally (+wolfram plugin sold me) and scripts just seemed more likely to to run with minimal edits. I&amp;#39;m a physicist, so a lot of simulations and mathematical modelling and  having latex and graph networks on screen helped more then auto too.</textDisplay></reply></replies></comment><comment><videoId>vfz-aXdLHUA</videoId><authorChannelId>UC0VyS4ooJkcTYaAFhPDRx1A</authorChannelId><textDisplay>The simulation is fractal &#128514;</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>&#8252;&#65039;</textDisplay></reply></replies></comment><comment><videoId>v_Mn9UIQaH4</videoId><authorChannelId>UCY9roooug82h_6P6ycPqh4w</authorChannelId><textDisplay>Please include links</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>the levels of consciousness yt video was in the description already and I just added the Siddhartha audiobook</textDisplay></reply><reply><authorChannelId>UCY9roooug82h_6P6ycPqh4w</authorChannelId><textDisplay>Oops I misunderstood, your reading your own notes in the beginning my bad</textDisplay></reply></replies></comment><comment><videoId>9D-YeaCjAnA</videoId><authorChannelId>UCvKrMolvBfE9t1SttGprcaQ</authorChannelId><textDisplay>That&#8217;s actually pretty cool. I wonder what the etymology of grokking is.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>comes from some sci-fi book written in the 80s. it&#8217;s a martian word that means something like &#8220;to understand deeply&#8221;</textDisplay></reply></replies></comment><comment><videoId>gDYjGSlcNUU</videoId><authorChannelId>UChBADDIselnEyjE_NFoLxlw</authorChannelId><textDisplay>man turn up tf bro&#128514; down in the ai dumps. fr tho hope you feel better og</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>lmao thanks</textDisplay></reply></replies></comment><comment><videoId>ge4YXbzGePY</videoId><authorChannelId>UCN3NAZ2WJ7Y6nJ-vm26sqcg</authorChannelId><textDisplay>I really thinks it is suspicious that now there are &amp;quot;papers&amp;quot; trying to discredited papers of competitors...</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>well yes but no, that&#8217;s just how the scientific process works. it&#8217;s only by attacking each other that we can &#8220;trim away the fat&#8221; and be left with assertions that stand up to scrutiny, aka the truth. when Galileo came around he was discrediting the prevailing scientific opinion that the sun rotated around the earth. don&#8217;t stop though, i certainly encourage you being suspicious of me, and you&#8217;ll notice i frequently point out ways in which i disagree with statements made in the papers i&#8217;m reading. thanks for the comment, hope you enjoyed the video!</textDisplay></reply><reply><authorChannelId>UCN3NAZ2WJ7Y6nJ-vm26sqcg</authorChannelId><textDisplay>Yes, your videos are interesting,  but let me disagree with your analogy (sorry, I&amp;#39;m not the best in english), but Galileo wasn&amp;#39;t &amp;quot;attacking&amp;quot; previous thruth. He was stating his own discovery. And he was sure he was right. Now you have people working to discredit people instead of working to discover new paradigms, new technologies etc... what a waste of time and money. The truth and fzcts,at the end, will prevail if we only focus on the result and the fact. If a model is worse than another one,  it will surely not survive.</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>as always i appreciate the further pushback but i think we may end up having to agree to disagree :) Scientists in Galileo&#8217;s time definitely considered his discovery an unreasonable insult to their own work at first. These authors have &#8220;discovered&#8221; that 81% of XAI papers do not confirm that their XAI methods are actually doing anything despite the fact that the creators of those LIME and SHAP methods specifically said their methods are not universally applicable and should only be used if tests confirm that they&#8217;re actually doing anything. &lt;br&gt;&lt;br&gt;Similarly, many physicists lately have been talking  about inconsistencies between the standard model and the new data coming out of the JWST satellite, but their criticisms have not been accompanied by a corresponding solution. Certainly it&#8217;d be great if every criticism was paired with an impressive replacement but it&#8217;s a lot easier to find a flaw in someone else&#8217;s work than it is to have a eureka moment, and pointing out flaws opens the way for someone else to have said eureka moment&lt;br&gt;&lt;br&gt;maybe we should leave the actual disagreement to the scientists who know how these technologies actually work so they can hash it out? :P Because i&#8217;m getting out of my depth here if i have to say anything more about XAI or these python libraries</textDisplay></reply></replies></comment><comment><videoId>t7r5JFKi2mI</videoId><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>These 15minute episodes are perfect</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hahaha the length is just based on how many papers caught my eye that day but noted</textDisplay></reply></replies></comment><comment><videoId>Iipo8YBek5M</videoId><authorChannelId>UCPSg2anrYSrDiqyPobe9YiQ</authorChannelId><textDisplay>Bro this channel is lit !&lt;br&gt;Keep on posting, that is my new research news feed.&lt;br&gt;Way more entertaining than scrolling arxiv.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hahaha thanks happy to hear you like it</textDisplay></reply></replies></comment><comment><videoId>u3Xt-Jy0ANQ</videoId><authorChannelId>UCUyoGvkqaXco6Jm-K4psU5Q</authorChannelId><textDisplay>hey do you use loom</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>nah just apple quicktime</textDisplay></reply></replies></comment><comment><videoId>3TOEBw4x2mo</videoId><authorChannelId>UCPSg2anrYSrDiqyPobe9YiQ</authorChannelId><textDisplay>Do you realize that by designing this many stepping AIs,  digesting that much data while having vanilla AIs on other side interacting with each other is pretty much like starting to build a realistic matrix</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>welcome, Neo &#128526;</textDisplay></reply></replies></comment><comment><videoId>3TOEBw4x2mo</videoId><authorChannelId>UCpaoen4mRE-5KrKzdt8XqLw</authorChannelId><textDisplay>Multi modality, no you shouldn&amp;#39;t train the same model for different in pu types (language, images). What you should do is usw a third model B as an intermediary betwen A ad C that can do a mapping between A&amp;#39;s embeeding space and C&amp;#39;s. The training should involve all 3 models A, B and C</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hmmmm interesting. i haven&#8217;t looked into multi-modality much at all so this is a cool concept i&#8217;m gonna have to look into. i assume the benefit here comes from having two separate embedding spaces? if so, id almost wonder if you can instead just take one model and allow it to use two separate encoders where the information can be combined in the residual space later. anyways i appreciate the info!</textDisplay></reply><reply><authorChannelId>UCpaoen4mRE-5KrKzdt8XqLw</authorChannelId><textDisplay>@@Tunadorable well, I am not an expert in this, but just thinking from my limited understanding. If you think of an AI art bot then what it must be doing is encoding a prompt to an embedding, then decoding that to an image. But it can&amp;#39;t respond to teh prompt in the same way as chatGPT can, because chatGPT decodes the embedding into a &amp;quot;next token&amp;quot;. So you have very different training data, and the embeddings are not compatible. So my suggestion was to train a third AI to translate from one embedding space to another. So if you say to chatGPT &amp;quot;draw me an image of a cat&amp;quot;, it can&amp;#39;t because it has no way to draw. But now you could say to Midjourney &amp;quot;/imagine a cat&amp;quot; and it could draw it. Now if you take theinternal state of both systems they should be equivalent so you can make a mapping from one to theother.,&lt;br&gt;Then the interesting part is when you give chatGPT a very complex prompt, which Midjourney cannot understand, an then map chatGPT state to MJ state</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>Would it not be more efficient to just ask chatGPT to write you a mid journey prompt? :P &lt;br&gt;&lt;br&gt;Not completely sure how this mapping would work. For example, when you provide the same prompt and chatGPT replies &amp;quot;I&amp;#39;m sorry, I have no way of actually drawing an image,&amp;quot; and mid journey replies with an actual image of a cat, then it certainly wouldn&amp;#39;t make sense to map one output to the other since they&amp;#39;re very different concepts, and midjourney likely has no place in its embedding space that looks anything like  the concept of &amp;quot;not being able to draw an image.&amp;quot; That rules out a possibility of an intermediate model mapping between output embedding spaces, although I think maybe your idea could work for inputs, but again why not just use ChatGPT as model B by asking it to write you a mid journey prompt?&lt;br&gt;&lt;br&gt;I think the real utility here with multi-modality comes with one model being able to do calculations on both input text and an input image. My understanding of multi-modality as it stands is that we can have for example two input streams, a middle that is combined, and then two output streams. So kinda like the shape &amp;gt;-------&amp;lt; and that this allows us to do things like ask a question about a provided image.&lt;br&gt;&lt;br&gt;Cool thought though; I have a feeling I&amp;#39;m still not grasping the full potential of what you&amp;#39;re saying. Would love to hear more in the future!</textDisplay></reply><reply><authorChannelId>UCpaoen4mRE-5KrKzdt8XqLw</authorChannelId><textDisplay>@@Tunadorable yes, this is an interesting discussion. OK, so maybe the examples I gave to illustrate (no pun intended) might have had you confused. What was really getting at is to map the embedding state of one system directly to an embedded state of another system, bypassing the input and output stages. So introduce a third system which learns how to do this mapping.&lt;br&gt;I find it somewhat difficult to imagine what the results of this would be, so finding examples is not easy, but let&amp;#39;s suppose you had an English ChatGPT, and a French ChatGPT. Now if you want to get them to communicate with each other, the English ChatGPT could translate into French and send the output to the French GPT, who could then respond and translate the response back to English (let&amp;#39;s suppose the translation only works one way), But now you have to train both systems to do the forward translation. &lt;br&gt;However, if you inserted a system between them, it could learn to map the English language embedding into a corresponding French language embedding and vice versa. In other words, the third system becomes a bilingual translator. Now you don&amp;#39;t need to do anything else. &lt;br&gt;The English chatGPT can run completely in English, the French ChatGPT can operate entirely in French, and the intermediary system learns to become this bilingual translator. And how does it do this? By machine learning! It learns these mappings by being trained. It doesn&amp;#39;t need to know anything about English or French, its inputs and outputs are just two embedded states.&lt;br&gt;How you would actually do the training to ensure the states map correctly, I don&amp;#39;t know. &lt;br&gt;Like I said i am trying to think of examples, and this is a very poor one becausechatGPT can do all of this internally, hence why my earlier example was with different modalities,language and image, A more interesting example might be connecting an image AI with a mussic AI, you show a picture to the  image AI and its embedded state is mapped toa state in the music AI. So you show the image AIa &amp;quot;sad&amp;quot; image and the music AI generates sad music, show it an image of people at a party it statrs making happy party music.,  and then progress to image sequences and you have a system for generating movie soundtracks, perhaps.</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>@@salsaman Loving the discussion. Feel free to bow out at any time but I&amp;#39;ll pick your brain for as long as you let me bc I like your ideas.&lt;br&gt;&lt;br&gt;So I think in the language case this would be pretty easy to train - just use google translate or human translators to compose a dataset of equivalent French &amp;amp; English sentences, get each of their embeddings for the French and English chatGPT models, and then yes a deep network should be able to pretty easily map one to the other and the calculations could even be run in reverse. Interestingly, I wonder if in this scenario it&amp;#39;d be helpful to do backdrop in both directions for a given data point? Might speed up training quite a bit to make this combination of two systems rather than training one larger model to simultaneously learn both languages. Very cool idea you&amp;#39;ve got going&lt;br&gt;&lt;br&gt;However, I&amp;#39;m not as clear how you&amp;#39;d construct such a dataset for fundamentally different modalities, as you said images and music. Many concepts in each embedding space wouldn&amp;#39;t have any corresponding potential representation in the other embedding space, so they&amp;#39;d essentially get lost and just function as noise in the training data.&#160;&lt;br&gt;&lt;br&gt;However, to jump off your idea of just picking up the idea of &amp;quot;sad&amp;quot; in both a photo and in music, I think there&amp;#39;s some potential here. Take whatever image and music datasets you want to do this for and run them through pre-existing classification models to get labels for &amp;quot;sad,&amp;quot; &amp;quot;happy,&amp;quot; &amp;quot;angry,&amp;quot; etc images and music. Then train your embedding &amp;quot;bridge&amp;quot; model with the goal of only translating the sadness vector or emotion subspace between the two embedding spaces. Now you&amp;#39;ve got a model to translate this subspace. The only major problem I see with this working is the extremely low signal-to-noise ratio (there&amp;#39;s vastly more information in a given image or song than just the emotion it conveys). However assuming we get past that, the real problem I see is purpose. What exactly would you use this emotion-specific image-music embedding space translation model for? To that end I still think the regular &amp;gt;----&amp;lt; model structure I brought up earlier still has more utility.&lt;br&gt;&lt;br&gt;Lmk your thoughts, I could happily poke around for holes all day cuz you&amp;#39;ve got some interesting ideas.</textDisplay></reply></replies></comment><comment><videoId>3TOEBw4x2mo</videoId><authorChannelId>UCfytgj1ay9QebhilPgn1uZg</authorChannelId><textDisplay>&lt;a href="https://www.youtube.com/watch?v=3TOEBw4x2mo&amp;amp;t=3m01s"&gt;3:01&lt;/a&gt; think making language model cheaper is quite foundational because current artificial neural networks are comparable energy inefficient compared to the brain indicating that their underlying computational paradigm is different though right now it is treated as engineering problem additionally efficiency impact the scaling of models.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>great point. but is their computational paradigm inefficient, or their computational substrate? there was a veritasium video awhile back talking about how if we switch from running the linear algebra as software on a GPU to embedding the weights within the voltages of a circuit then the energy consumption becomes negligible. however, this does require specialized hardware and the willingness to never update the model again. i predict that there will be many more ways invented to do this stuff, and within 2 or 3 years we&#8217;ll probably be running GPT4 if not 5 locally on our smartphones</textDisplay></reply><reply><authorChannelId>UCpaoen4mRE-5KrKzdt8XqLw</authorChannelId><textDisplay>@@Tunadorable not suggesting this as a practical solution, but a chatGPT using hydraulics would be fun, there are precedents for this  &lt;a href="https://en.wikipedia.org/wiki/MONIAC"&gt;https://en.wikipedia.org/wiki/MONIAC&lt;/a&gt;</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>@@salsaman hahahaha so fun. I&amp;#39;d love to see a super intelligent AGI wake up only to realize that we&amp;#39;re running it on a massive hydraulic processor. Good luck performing infinite self-replication and exterminating humanity now :P</textDisplay></reply></replies></comment><comment><videoId>-Qg7zCupgrw</videoId><authorChannelId>UCkgbcnVWuHIV0uXz11WUl8A</authorChannelId><textDisplay>Dude check your volume it&amp;#39;s super low. Excellent content tho</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>thanks i&#8217;ll look into upping the gain on my mic</textDisplay></reply><reply><authorChannelId>UCkgbcnVWuHIV0uXz11WUl8A</authorChannelId><textDisplay>@@Tunadorable check out Adobe&amp;#39;s AI stuff for audio enhancement. I think if you up the gain you&amp;#39;ll introduce distortion IDK audio isn&amp;#39;t my forte. It sounds fine just seems like it was too far away or something.</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>@@lexscarlet Yeah I think you&amp;#39;re probably right about the mic being too far away, thanks!</textDisplay></reply></replies></comment><comment><videoId>wc3TFf-HnH0</videoId><authorChannelId>UCRfCFH4cTB5OzH519cxdGEA</authorChannelId><textDisplay>Thanks for sharing!</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>thanks for watching!</textDisplay></reply></replies></comment><comment><videoId>XE1BHFEbJJE</videoId><authorChannelId>UCw93vPinPMJfFpx49bl7JHw</authorChannelId><textDisplay>The banks condition in the US so scary &#128561;&#128561;&#128561;</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>Right!</textDisplay></reply></replies></comment><comment><videoId>yaShsmi35pU</videoId><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>You should start a discord eventually</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hahahaha someone didn&amp;#39;t watch the entire video go click on my linktree in the description</textDisplay></reply><reply><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>@@Tunadorable cool</textDisplay></reply></replies></comment><comment><videoId>yaShsmi35pU</videoId><authorChannelId>UCqNgKyaf0mi86dBR0pWVNBQ</authorChannelId><textDisplay>Amazing!&#129321;&#129321;&lt;br&gt;I look forward to your future updates and endeavors! You will succeed.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>thanks!!!</textDisplay></reply></replies></comment><comment><videoId>yaShsmi35pU</videoId><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>How do you pronounce the channel name</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>like the two words tuna and adorable. Last name is Tunador and this is just a fun lil nickname I&amp;#39;ve been using on social media handles. tempted to change it to tunadork given the channel&amp;#39;s content</textDisplay></reply></replies></comment><comment><videoId>Me9QzADq2tc</videoId><authorChannelId>UCHr8qa00aqkpK875KesUMKA</authorChannelId><textDisplay>Cooooollll i love it the way that you share and simplify the infos &#10084;&#10084;&#10084;</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>thanks glad you like it! feel free to suggest topics if there&#8217;s anything specific you&#8217;re interested in</textDisplay></reply></replies></comment><comment><videoId>F0cbxnHEoS8</videoId><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>My brothers take was who cares they will probably serve the smaller model to most people most of the time due to cost these large models are just publicity stunts. Literally his company did a similar thing after time of offering better ai they realized that a fine tuned 3b model would good enough and way cheaper.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>facts, until x years from now when the impressive model is actually both capable and cheap enough to replace entire jobs. Throw gemini ultra on a Boston dynamics kill machine and you could replace plenty of factory safety technicians (not sure I have the correct name for that position) for example, since their job can often boil down to checking dials and adjusting knobs accordingly</textDisplay></reply></replies></comment><comment><videoId>F0cbxnHEoS8</videoId><authorChannelId>UCWMbYGGCXzz8YieTVrwkj7Q</authorChannelId><textDisplay>I hate to say it, but in science optimism far outpaces reality. There is a high likelihood that both OpenAI and Google are near the limits of the transformer architecture and current computing  power. While their public messaging may suggest rapid progress toward human-level AGI, many leaders in the field present a more measured perspective. They explain how today&amp;#39;s AI still just comes down to mathematical computations, rather than truly thinking like a human. I think OpenAI and Google&amp;#39;s next focus should be developing tools to integrate their platforms with functional tasks. I am talking about Zapier-like functions that are inherent with Gemini and GPT-4 without having to have a separate Zapier account.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>I definitely agree about a potential limit to the transformer architecture &amp;amp; current computing power. Sam hinted months ago that the predicted scaling curve started falling off with GPT4 and ofc everyone&amp;#39;s thinking so much about linear attention. &lt;br&gt;&lt;br&gt;I don&amp;#39;t agree on the thinking like a human thing though, AGI might end up thinking very differently from humans. I&amp;#39;m of the opinion that while human intelligence is the best we&amp;#39;ve seen so far and there&amp;#39;s a lot to be learned from the brain&amp;#39;s architecture, it&amp;#39;s very possible that human intelligence is sub-optimal given its recency in the evolutionary timeline and the inefficiency of natural selection as an optimization algorithm.&lt;br&gt;&lt;br&gt;But yes for sure tools will be huge. GPT3 finished training in 2020 but we didn&amp;#39;t see widespread use until OpenAI created an interface in the form of instruct tuning, RLHF, and an easy to use website. The next group of startups will be finding very clever ways to use these models that we have not yet thought of.</textDisplay></reply><reply><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>&#8203;@Tunadorable I think that if want smarter machines they won&amp;#39;t be in real time</textDisplay></reply><reply><authorChannelId>UCWMbYGGCXzz8YieTVrwkj7Q</authorChannelId><textDisplay>@@Tunadorable It&amp;#39;s interesting to consider AGI and how its intelligence might be different from human intelligence. We hope that AGI will be noticeably smarter than humans. If it isn&amp;#39;t, there&amp;#39;s a risk that those who have been predicting the arrival of AGI might claim it has been achieved, even if it is completely inferior.</textDisplay></reply><reply><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>I don&amp;#39;t think its architecture looks at phi-1 or orca and read beyond neural scaling laws. We can scale the weights up fast the we can scale data quality.</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>I said different from human intelligence and then you seem to have jumped to &amp;quot;different&amp;quot; implying &amp;quot;inferior.&amp;quot; To be clear that is in no way what I meant. I&amp;#39;m not sure how a thing could by definition be AGI if it were inferior to humans (or at least to the median or XXth percentile human). What I mean is that the &amp;quot;flavor&amp;quot; of intelligence it has may be very very different. It might not think the way we do, but still be very very smart. From there all types of scenarios occur (misaligned, buddha-like-figure, Spock, something completely alien, etc.) But whatever it is I think it can get far smarter than us</textDisplay></reply></replies></comment><comment><videoId>e04YLiAIgqo</videoId><authorChannelId>UCG4bhQBtyt6cRsiscSrMs1g</authorChannelId><textDisplay>recently youtube has given me the most interesting videos with fewer views than normal, love it.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>happy to have you!</textDisplay></reply></replies></comment><comment><videoId>e04YLiAIgqo</videoId><authorChannelId>UC6BtcjFEMW_Y2gJb2twBmXw</authorChannelId><textDisplay>Stop thinking so hard</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hahahaha no</textDisplay></reply></replies></comment><comment><videoId>3pKUnE3zaB8</videoId><authorChannelId>UCZwss_6zfKmKUdU9s51f3sg</authorChannelId><textDisplay>I have been doing this sort of research for a number of years, your approach isn&#8217;t dissimilar to the approach I originally took, good luck!</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>Thanks! Any chance you were able to turn it into a career? Very unemployed rn &#128517;</textDisplay></reply><reply><authorChannelId>UCZwss_6zfKmKUdU9s51f3sg</authorChannelId><textDisplay>&#8203;@@Tunadorable more or less I am amd have yes, the time is better than ever now that there is a lot of public interset, if you tried to talk about these things a couple of years ago, people thought you were nuts</textDisplay></reply></replies></comment><comment><videoId>tht0a8VMCGI</videoId><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>Could try prompt it with explanation rather then summaries because it maybe a list of the key ideas/take aways rather then just a condensed format.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>that&#8217;s what Dave Shapiro&#8217;s original repo that i ripped this off of did. it was something like &#8220;what are the key takeaways for a CEO&#8221; and i tried a few other variants on &#8220;what are the implications&#8221; or &#8220;please explain&#8221;. I wasn&#8217;t too fond though because every answer becomes &#8220;this makes AI more efficient&#8221;, &#8220;this makes AI more capable&#8221;, etc. when i do literally want to know the summary. The end of the responses actually do contain something more resembling implications/explanations but i hardly ever get to that point because I find all i want from the beginning summary.</textDisplay></reply><reply><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>@@Tunadorable That&amp;#39;s very interesting. I will try experiement and see if I come up with anything.</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>bet lmk if you do i wouldn&#8217;t be surprised if im just incompetent at prompt engineering</textDisplay></reply></replies></comment><comment><videoId>tht0a8VMCGI</videoId><authorChannelId>UCrHn-qXmDUnXaX7AzUmFOiw</authorChannelId><textDisplay>Do you think within the next year you will be able to pass in a 3b1b playlist and the summary, as a prompt, and get a visualized summary in video format?&lt;br&gt;Also love the idea of daily AI papers</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>is 3b1b referring to the YT channel 3blue1brown? If so my best understanding of what you&amp;#39;re asking for is a visual tldr for his videos. The answer is fs yes, in fact you could probably script up a pretty buggy version of it right now. Script should download the videos, separate audio, pass audio through speech-to-text like Whisper, then have GPT-4 summarize and use advanced data analysis to code up some fast-forwarded python scripts of the topic being discussed. An intelligently split-up summary might even allow multiple visuals for one summarized video. Trouble would be getting a high enough success rate on each python visualization, but that&amp;#39;s probably very doable with a multi-agent setup like Microsoft&amp;#39;s new Autogen. &lt;br&gt;&lt;br&gt;Thanks for the interesting comment! I hope I understood your question correctly &#128517;. Consider joining my discord, only about a dozen people but they&amp;#39;re all very active &amp;amp; knowledgeable and have this kind of discussion on the daily. link in description</textDisplay></reply></replies></comment><comment><videoId>tht0a8VMCGI</videoId><authorChannelId>UCmG7BdQ6kcW4z5AxZZ6S3xA</authorChannelId><textDisplay>Regarding partial rerunning: could you enumerate all steps during a CoT and later on say &#8220;replace step x with this:&#8230;.&#8221; ?</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>In my experience LLMs have trouble referencing and editing anything that&amp;#39;s been enumerated; I think this has to do with being next-token optimizers but maybe I just haven&amp;#39;t been using the right prompt. I ran into this issue when trying to get them to get them to generate chapter timestamps for my YT videos, it was basically hopeless. Might be easier to just prompt them to output their CoT in a specific markdown format by asking them to match a text string like this &amp;quot;#. &amp;lt;First bullet point&amp;gt;\n#. &amp;lt;Second bullet point&amp;gt;\n...#. &amp;lt;Final bullet point&amp;gt;&amp;quot; and then using a script (assuming your accessing through API instead of the chat website) to have them start again from that given point. Combine that with some kind of RL based prompt-optimizer and MAYBE there&amp;#39;s an idea here. Great question! And I&amp;#39;m certainly not qualified to be answering it &#128513; &lt;br&gt;&lt;br&gt;Consider joining my discord, only about a dozen people but they&amp;#39;re all very active &amp;amp; knowledgeable and have this kind of discussion on the daily. link in description</textDisplay></reply></replies></comment><comment><videoId>OYKH2xrtd7U</videoId><authorChannelId>UC_GcARVOMVGOceIissDUdKQ</authorChannelId><textDisplay>Neural network parameters are fixed precision. Some of these patterns will be due to running out of bits.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>yes!!!! hahaha it&#8217;s been too long since i learned about how flops are calculated and a couple other commenters have alluded to this but i appreciate you giving a confident answer and an explanation. i think you&#8217;re right the banding must certainly be caused by running out of bits.</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>legitimately this is why i like posting these things to the internet, so i can be critiqued and corrected rather than spend 6mo pursuing an idea that&#8217;s not gonna go anywhere (in this case the banding)</textDisplay></reply><reply><authorChannelId>UChVnzNqEWXmxqAm6d-SiH0A</authorChannelId><textDisplay>Here&amp;#39;s the thing... youre actually not wrong at all, in fact I think your intuition was dead on... I have had this crazy intuition that digital nns will eventually plateau at best no matter how many parameters you&amp;#39;ve got. &lt;br&gt;&lt;br&gt;Your intuition i believe is that consciousness arises from something with an infinitely complex fractal characteristic.&lt;br&gt;&lt;br&gt;Suppose you built a neural network but with a completely analog signal path? Op amp functional blocks or even a clever discrete transistor design. You get infinite numerical precision (even the aptly named transcendentals) plus you get the noise that neural nets need to escape local minima in the loss landscape while training, for free along with it.&lt;br&gt;&lt;br&gt;I think anything based on approximations of this is extremely useful, but will lack the ability to outperform analog intelligence ultimately.&lt;br&gt;&lt;br&gt;Weird theory right? What gave you the fractals idea? You wouldn&amp;#39;t believe how the analog nn thing arrived in my head...</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hahaha not sure if i said that in the video but you&#8217;re dead on with my intuition. where does that intuition stem from? literally visions lmao that&#8217;s about all i can say&lt;br&gt;&lt;br&gt;idk enough about analogue systems to completely follow you but this idea that the increasing size of NNs will eventually plateau in performance is already partially backed up i believe. ik with GPT3 it&#8217;s loss fell ever-so-slightly off the scaling law prediction and i think i heard sam altman hint months ago that GPT4 with text only had an even larger plateau, which is why they were originally saying they didn&#8217;t have plans to make GPT5. &lt;br&gt;&lt;br&gt;you should join my discord if you&#8217;d like to discuss more ideas like this!</textDisplay></reply></replies></comment><comment><videoId>OYKH2xrtd7U</videoId><authorChannelId>UCpQhzdXPXq_tar_plYm5XJw</authorChannelId><textDisplay>I feel like that those lines are there because in those regimes of x1 and x2, the later part of the network has neurons that are on the edge of firing/not firing with their relu, and based on that the even later layers can have very different mechanincs.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>but what does it mean to be on the edge of firing/not firing? There&amp;#39;s no inherent randomness, meaning such a deterministic system shouldn&amp;#39;t freak out that much from a ReLU. But then as some other commenters have pointed out, there&amp;#39;s probably error introduced by extremely small floating point operations, and I&amp;#39;m guessing that&amp;#39;s what you&amp;#39;re referring to. Great point!</textDisplay></reply><reply><authorChannelId>UCpQhzdXPXq_tar_plYm5XJw</authorChannelId><textDisplay>@@Tunadorable no, I mean when a neuron doesn&amp;#39;t fire, it&amp;#39;s output is 0 because of the relu. But when it starts firing, it&amp;#39;s output is suddenly infinitely larger than 0.. I&amp;#39;m just saying that I can imagine that 0/not 0 could make funny things because of the neurons that depend on it&amp;#39;s output. I&amp;#39;m really not sure about this one though, I&amp;#39;m just speculating.</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>Aaaah I see interesting point. Will have to add it to the ongoing list of things I didn&amp;#39;t think of here :)</textDisplay></reply></replies></comment><comment><videoId>OYKH2xrtd7U</videoId><authorChannelId>UCjbvu6UuAMfGOjQGPQ2guxg</authorChannelId><textDisplay>This is an interesting idea and I think your intuition is well directed, however on your terminology, mathematically, you&amp;#39;re referring to chaos rather than fractals. Chaos is where a system has sensitive dependence on initial conditions. That is, arbitrarily small chances in the initial state can lead to massive changes as the system moves forward in time. This is why we see the pendulum infinitely changing colour as we zoom further and further. Fractals are self recursive, very pure, mathematical objects which I think are unlikely to come up in loss landscapes. &lt;br&gt;&lt;br&gt;With it in mind that we are looking for a sensitive dependence on initial conditions, it would seem to me this is indicative of a over parameterised neural network, towards the peak of the double descent test loss. I wouldn&amp;#39;t be too surprised if chaos in loss learning has been at least alluded to in the literature and definitely its worth checking.&lt;br&gt;&lt;br&gt;It worth noting, as others have pointed out, sensitive dependence deals with arbitrarily small values which is in opposition to the finite precision offered by computers, which makes an empirical study somewhat of an uphill battle.&lt;br&gt;&lt;br&gt;Nice video! :)</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>haha yes certainly fantastic comment&lt;br&gt;&lt;br&gt;I was in fact referring to chaos, but also fractals. Believe it or not I majored in math and do (kind of) understand the difference, but you probably shouldn&amp;#39;t believe me given how my loose use of terms is so out-of-character for such a background. The issues with my terminology you found come from a combination of 1) me being rusty on the subject, 2) me preferring to use metaphors, words that are only tangentially related, and generally loose speech as a way to foster creativity, and 3) the word fractal is more fun and makes a better YouTube thumbnail. However my reasoning here is shaky at best, so I totally do expect a rational bystander to say you made the better point&lt;br&gt;&lt;br&gt;Let&amp;#39;s disagree for now about fractals showing up in loss landscapes. It&amp;#39;s not something I&amp;#39;m confident in, but do have a very interesting intuition behind which I will be revealing later.&lt;br&gt;&lt;br&gt;Again yes you&amp;#39;re totally right, a legitimate scientist would be doing proper background research into chaos in the learning process before publicly making claims or sharing ideas&lt;br&gt;&lt;br&gt;Certainly floating points are an issue here and if I remember correctly I alluded to such in my video. Of course chaotic behavior can in fact easily be shown in far simpler computer systems such as a Lorenz system simulation, but whether the same effect would be more difficult to tease out in something with as many parameters as an LLM is a great question. Some other comments have proposed ideas such as forcibly converting all tensors to float64 or float128, or training a simpler model from scratch to use a higher fp&lt;br&gt;&lt;br&gt;Again fantastic comment, consider joining my discord if you&amp;#39;d like to discuss more and with more people. link in vid description</textDisplay></reply></replies></comment><comment><videoId>OYKH2xrtd7U</videoId><authorChannelId>UCWgHfVKLxORf9rRVnBp13aA</authorChannelId><textDisplay>This was very interesting, I believe what you saw was float precision noise though,&lt;br&gt;&lt;br&gt;I think the experiment can be made more analysable and precise, use a recurrent mnist model with 64 bit float precision, not sure that exists though so you may have to cobble your own, with that you should be able to zoom in much much more</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>yes some other commenters pointed out the floating point problem and i think you&#8217;re right there&lt;br&gt;&lt;br&gt;good idea. the point here is embeddings so i&#8217;m not familiar enough with vision to know that they don&#8217;t have embeddings but i think for NLP the equivalent of would be to train a tiny recurrent transformer on wikidata or even tiny shakespear with float64&lt;br&gt;&lt;br&gt;unfortunately though, if my hypothesis is right then the structure i&#8217;m looking for would be more likely to show up in more complicated models, so i may even have to download an open source LLM and forcefully change all of the tensors to float64 &lt;br&gt;&lt;br&gt;thanks for your input good stuff! if you&#8217;d like to discuss more feel free to join my discord, link in vid description</textDisplay></reply><reply><authorChannelId>UCWgHfVKLxORf9rRVnBp13aA</authorChannelId><textDisplay>@@Tunadorable i was more thinking of rolling out the image into a single line of &amp;quot;tokens&amp;quot; and embed from there, although I think you&amp;#39;re right with perhaps needing more complicated models so perhaps it&amp;#39;s mute anyway,&lt;br&gt;&lt;br&gt;I don&amp;#39;t know enough about floats to tell how much different a network will behave when you essentially change how it&amp;#39;s math is done, but it&amp;#39;s not out of my imagination that a network can come to rely on the float quirks and in that case the network would basically fall over, so that&amp;#39;s something to look out for</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>ooooh another great point there</textDisplay></reply></replies></comment><comment><videoId>OYKH2xrtd7U</videoId><authorChannelId>UC6R4xs5XT4nkzhhrH6z_8yQ</authorChannelId><textDisplay>This isn&amp;#39;t my area of expertise, so forgive me if my terminology is off.&lt;br&gt;&lt;br&gt;As soon as I heard your premise, it made intuitive sense to me, but that might have been from the Newton fractal you had on the screen. When you showed the banding, my first thought was that it might have been related to the transfer function, but I like what the other commenter said about floating point precision too. Do you have a sense of how close you are to the limit of precision? &lt;br&gt;&lt;br&gt;Another thought, related to the comment of simulating recurrence with feed forward networks, I suspect that every layer of the network functions as a layer of recursion. So when GPT said there wasn&amp;#39;t any recursion, I think that isn&amp;#39;t quite true. Because the networks are finite in size, I think the fractals will have a limit to their complexity, similar to how we commonly include an iteration cap when rendering the Mandelbrot set. I also suspect that since the layers are different, it might be comparable to using different functions on each iteration of the Mandelbrot set. &lt;br&gt;&lt;br&gt;I&amp;#39;m curious to see how this evolves in the future.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>thanks!!!! yes the other commenter who specifically said &#8220;running out of bits&#8221; was able to properly trigger my memory for how flops work from the math class a few years ago. &lt;br&gt;&lt;br&gt;and you&#8217;re way ahead of me on the recursion thing. one thought i had and i think another commenter mentioned was that i should try this with a larger deeper model. maybe a 7b+ parameter would engage in more recursion and actually have some visible fractal-like patterns. &lt;br&gt;&lt;br&gt;pls join my discord if you&#8217;d like to discuss more, link in vid description!</textDisplay></reply></replies></comment><comment><videoId>OYKH2xrtd7U</videoId><authorChannelId>UC0Um9zTOB0P9nDaZP9imRlw</authorChannelId><textDisplay>Theres a chance the gpt model itself might not have enought resolution even if you try to increase the resolution of the &amp;quot;photo&amp;quot; of the model. It would be like trying to take a 100mpixel photo of a 2mpixel photo, all you&amp;#39;d get would be a 100mpixel photo of a 2mpixel pjoto of the possible space the model was molding itself to.</textDisplay><replies><reply><authorChannelId>UC0Um9zTOB0P9nDaZP9imRlw</authorChannelId><textDisplay>@&lt;a href="https://www.youtube.com/watch?v=OYKH2xrtd7U&amp;amp;t=22m00s"&gt;22:00&lt;/a&gt; agree, exactly.&lt;br&gt;&lt;br&gt;&lt;br&gt;Also also, are you sure you are not trying to take a 2d picture of a n-space structure?</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>I am certainly taking a 2d picture of a high dimensional structure, but at least for this initial exploration I don&#8217;t really have a better option. Will definitely look into alternatives though, chatGPT suggested that there exist statistical analyses meant to help us learn things about high dimensional structures which we can&#8217;t observe from low dimensional slices.&lt;br&gt;&lt;br&gt;As far as the resolution thing goes, I&#8217;m var from an expert in floating point operations but I believe the calculations should technically work just fine. Now was gpt2 designed to have this done to it, or to have any kind of interesting structure at these borders? Certainly not, but that&#8217;s why discovering said structure would be so interesting. I am thinking about testing this out with a larger model that might have different characteristics in its embedding space,but that&#8217;s relatively far down on the todo list given the compute it will require.&lt;br&gt;&lt;br&gt;Great points you&#8217;ve got here love to discuss more. If you&#8217;re interested then I&#8217;d recommend joining my discord, link in vid description</textDisplay></reply></replies></comment><comment><videoId>OYKH2xrtd7U</videoId><authorChannelId>UCfSLd-DGt3fD2BwJ20Y4YoQ</authorChannelId><textDisplay>Couldn&amp;#39;t interesting patterns on the boundaries come from floating point errors? There could be systematic patterns to these having to do with the details of how the last decimal places are calculated while at the largest scale still being stochastic</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>i don&#8217;t know enough about floating points but i do think you&#8217;re right that they may create their own bit of randomness if a given flop is not 100% repeatable. my impression is that even running the same experiment on a different gpu may result in a different result but idk enough about hardware kernels to speak to that. However, at the largest scale we should (by boring theory) be seeing a deterministic clean break rather than stochasticity. i could be wrong since i am talking out my ass, but i&#8217;m under the impression that i didn&#8217;t go small enough to run into this many flop errors to the point of creating data that looks this stochastic. my current best working theory is that there&#8217;s a small degree of simulated recurrence, aka of each transformer layer doing a similar computation to the last, that&#8217;s creating this odd behavior. however, at least so far, it doesn&#8217;t seem to be enough recurrence to create a properly fractal system. would love for u to jump on my discord and discuss more, link in video description!</textDisplay></reply></replies></comment><comment><videoId>OYKH2xrtd7U</videoId><authorChannelId>UCYisCon9PocQRV1UZxKKaGg</authorChannelId><textDisplay>My background is in Physics, not machine learning, so please correct me if I&amp;#39;m wrong&lt;br&gt;&lt;br&gt;This &amp;quot;Loss landscape&amp;quot; is a way to visualize all the possible loss function we could give to a neural network&lt;br&gt;&lt;br&gt;Before it was thought that the knowledge of a Neural Network was held in the network, the weights and biases, but you are saying that the knowledge is held in how the information is represented as vectors (embeded) and that the layers of the network are just operators moving that vector around in embeding space. Sounds a lot like quantum mechanics&lt;br&gt;&lt;br&gt;In Quantum Mechanics the information about a particle is held in the Wavefunction, which is a vector, and then the measurements are represented as matrix operators that rotate that vector&lt;br&gt;&lt;br&gt;Then if the loss landscape has fractal crevices it means that there are vectors that are very close to each other in embedding space but they represent entirely different situations, resulting in extremely different values for the loss function&lt;br&gt;&lt;br&gt;This part is actually quite different from Quantum Mechanics, or at least I don&amp;#39;t know of anything similar</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>if anyone wants to read my response to this comment you&#8217;ll have to check out the discord</textDisplay></reply></replies></comment><comment><videoId>OYKH2xrtd7U</videoId><authorChannelId>UCQrgD46yjxzI6iOciYuBz5w</authorChannelId><textDisplay>Really interesting stuff! Looking forward to seeing where you go with this. It would be good to see the result replicated on different hardware.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>ooooh good idea. maybe switch from the T4 gpu using pytorch with GPT2 to a different model that uses tensorflow on google colab&#8217;s V100?&#129300;</textDisplay></reply></replies></comment><comment><videoId>ghAmn6dKwA4</videoId><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>I think that the 1 trillion parameter model the goverment is training scares me more especially everthing we know about neural scaling laws.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>where have you heard about this? what gov&amp;#39;t agency? I&amp;#39;ve been relatively unafraid of the gov&amp;#39;t just because I feel like we would&amp;#39;ve heard if a significant number of AI researchers were hired by the feds and if a big enough order came in to Nvidia for chips, but maybe I missed it?</textDisplay></reply><reply><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>@@Tunadorable sciencegpt by the Argonne National Lab</textDisplay></reply></replies></comment><comment><videoId>ghAmn6dKwA4</videoId><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>But gemini is doing a similar thing combining q learning and lllms.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>yes I was referring specifically to OpenAI but I&amp;#39;m scared of all corporations</textDisplay></reply></replies></comment><comment><videoId>JKLSi8xci30</videoId><authorChannelId>UCQKbzFNT1Qvh4pFNUshlrXw</authorChannelId><textDisplay>Interesting. By publishing original research, where do you (plan to) submit your articles to? Do you just publish preprints on pages like arxiv or do you submit them to some scientific journal / conference? Are you the only author in that case? I have thought about doing some research on my own and publishing articles about my research as well, but I&amp;#39;m not really sure how and where I would submit them, should I even finish writing a paper.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>for most fields I would recommend you submit to traditional journal. you&amp;#39;ll have some difficulties at first not knowing the conventions and likely not writing up to their standards, but if you can legitimately produce something of quality and find a journal that sufficiently matches your topic then they will consider you for publication. unfortunately the process takes months to hear back plus multiple revisions and they demand that you only submit to one at a time, so I wish you good fortune on the potentially year+ long journey.&lt;br&gt;&lt;br&gt;in AI, publishing to journals is a bit of an afterthought. certainly academics still do it because it&amp;#39;s the convention and a requirement for their jobs &amp;amp; for gaining tenure. But if all you care about is that people read and cite it, as I do, then publishing to arXiv is the way to go. I read recently that somewhere between a quarter and a third of AI papers published to arXiv never get sent to an actual journal. In reality no on one in the field really waits to read journal publications months later, they just check the newest arXiv papers of the day like I do in my weekly paper summary videos. AI is moving far too fast to care about traditional peer review&lt;br&gt;&lt;br&gt;Rather than a full review process arXiv uses what they call endorsements where certified endorsers (people who&amp;#39;ve published to arXiv multiple times and been granted the title) can skim / lightly read your article rather than actually tear it apart as a journal would do, and based on that skimming they can endorse your article for publication. All they&amp;#39;re checking for is that your paper is on-topic for the arXiv category you&amp;#39;ve submitted, and that it&amp;#39;s not obviously majorly flawed. If you submit something that&amp;#39;s poorly written/formatted, completely nonsensical, totally off topic, or clearly demonstrates you&amp;#39;re not caught up enough with forefront knowledge in the field to create anything of substance, then they&amp;#39;ll reject. This process is much easier if you know an endorser (I happened to meet a bigwig this past summer who I&amp;#39;m hoping will be mine) but if not then you can request endorsement through the website by a specific researcher in your category who is listed as an endorser.</textDisplay></reply></replies></comment><comment><videoId>JKLSi8xci30</videoId><authorChannelId>UC57xUck05N-uEcqUolJnrKw</authorChannelId><textDisplay>chad makes another channel update</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>&#8252;&#65039;</textDisplay></reply></replies></comment><comment><videoId>JKLSi8xci30</videoId><authorChannelId>UCrZ-KqiEy49hCtPyTEkGcjQ</authorChannelId><textDisplay>DAWGO. I LOVE YOUR ENERGY. GOTTA BE INSANE TO ACHIEVE SOMETHING SIGNIFIGANT. DEAR GOD DAWGO YOU HACE INSPIRED THE FRICK OUT OF ME. I AM PROUD TO BE A TUNADORK. THE WAY YOU EXPRESS AND CONVEY YOUR IDEAS IS WILD. I AM SO SCATTERBRAINED I DONT UNDERSTAND HOW YOU CONVEY SO ELEGANTLY. HAVE A GOOD DAY CHANGE THE WRLD</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>yo thanks &#129392;</textDisplay></reply></replies></comment><comment><videoId>JKLSi8xci30</videoId><authorChannelId>UCgOHztsC-Z1d5foAPdi5WOA</authorChannelId><textDisplay>ok that&amp;#39;s a crazy Obsidian Canvas setup. even with chatgpt embedded in my canvas I&amp;#39;m not that productive wth &#128128;</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hahahaha i love drawing the lines they make me feel so smart</textDisplay></reply><reply><authorChannelId>UC57xUck05N-uEcqUolJnrKw</authorChannelId><textDisplay>@@Tunadorable big relate</textDisplay></reply></replies></comment><comment><videoId>e_xD_K1wSZ4</videoId><authorChannelId>UCuXE9iqEKWRQxuIR4GEq3wA</authorChannelId><textDisplay>Yo this channel is good man. I&#8217;m the first like?? No way. I&#8217;m a subscriber now</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hahaha thanks pretty wide variance in how well the videos do. i appreciate it!</textDisplay></reply></replies></comment><comment><videoId>N7StIjJmm4M</videoId><authorChannelId>UCD_HZ8yaiGl5DWDnOZtSZCQ</authorChannelId><textDisplay>im liking these videos</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>haha thanks there will be plenty more. the idea is really just to force myself to study by making a public commitment, the fact that i&#8217;ve gotten a couple dozen views is a surprise. lmk if there&#8217;s any specific topics you&#8217;d be interested in</textDisplay></reply><reply><authorChannelId>UCD_HZ8yaiGl5DWDnOZtSZCQ</authorChannelId><textDisplay>@@Tunadorable I am a math and computer science graduate so anything to do with ai is fine or coding just do you.</textDisplay></reply></replies></comment><comment><videoId>LwEahYNT9HQ</videoId><authorChannelId>UCO9twdyvuX32ZNCiPc1xVCg</authorChannelId><textDisplay>Hey man I was thinking about what you said how &#8220;the intelligence seems to be from the movement through the embedded space.&#8221; May have misquoted. Sorry if I did. I can&#8217;t help but think of the human brain and how it takes in raw data and process it one area of the brain then moves it to another for more processing before ultimately making its way to the prefrontal cortex. That said. Could you take those paths and create token from the path. Given different models ie vision model, language model, sound model etc. Then put those paths together in new tokens and feed to a higher level model that processes all the paths leading to a more robust system? If what I said is retarded I apologize. This way above me lol</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>Not too fond of that R word but I don&amp;#39;t think what you&amp;#39;re saying is dumb, and this stuff is above my pay grade too lmao. I can&amp;#39;t say I fully understood what you&amp;#39;re getting at in detail but at a broad level yes, aggregation whether it be across the input context or between models is certainly a potentially fruitful area of research. That&amp;#39;s reminiscent of what they did towards the end of this video, test to see if they could aggregate/summarize the info to be fed into the models rather than giving each model the fully detailed information. Not sure how exactly you would tokenize a string of computations moving through a model though, I&amp;#39;d recommend diving more into the math if you think you have an idea and want to be able to thoroughly explain it. Best of luck if you decide to do so!</textDisplay></reply></replies></comment><comment><videoId>Yty64xj0tXg</videoId><authorChannelId>UC93KynvTA5V71DAeEI2mQlg</authorChannelId><textDisplay>Cool video! I wish I had the time to read the whole paper, looks very interesting! I especially liked the discussion from about 22 minutes to the end.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>thanks!</textDisplay></reply></replies></comment><comment><videoId>Yty64xj0tXg</videoId><authorChannelId>UCwh2x16OccSGeKSlxggvVmw</authorChannelId><textDisplay>Thanks for reading this paper so I don&#8217;t need to</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hahaha happy to help</textDisplay></reply></replies></comment><comment><videoId>Yty64xj0tXg</videoId><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>You need to stop dropping classics like this when need to get other work done&#128514;</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hahahaha duly noted and I think you&amp;#39;ll be excited about tomorrow&amp;#39;s video&#128064;</textDisplay></reply></replies></comment><comment><videoId>UpZoc0HNQEg</videoId><authorChannelId>UCULDvOtpquFuAahBhZr8j2g</authorChannelId><textDisplay>Great video man. You&amp;#39;re young and intelligent. Quick question. What do you think will happen with the economy? are we heading towards ai communism or techno feudalism?</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>haha thanks! my education and work experience is actually in economics funnily enough. &lt;br&gt;&lt;br&gt;as a background i do think multimodal llms will be capable enough to replace the vast majority of white collar jobs within the next five years if not sooner. ofc it takes more time to fully implement any new tech. i also think there&#8217;s a good chance that robotics technology will progress enough for the same to eventually happen in manufacturing and maybe even eventually the trades. the only thing left will be jobs with an intrinsic human dimension; we&#8217;ll have a &#8220;made/performed by humans&#8221; label just like the current &#8220;made in america&#8221; one.&lt;br&gt;&lt;br&gt;as far as whether this massive job loss results in ultra luxury automated space communism or techno feudalism/corporatism, it depends on how the governments react. there are some proposed regulations that will have a positive impact such as requiring &#8220;made by AI&#8221; labels on products and services. however i&#8217;m not optimistic given 1) the history of regulatory capture in america, 2) the rate of change being too fast for legislatures to keep up and 3) a significant portion of America&#8217;s rules being implemented in a reactive manner through case-law in a system that already gives undue power to corporations. europe does not suffer from 1 or 3, and china of course has its own even more drastic problems. basically, if open-source is HIGHLY encouraged then i think we&#8217;ll be okay long term despite a period of chaos (when open source models assist with phishing, hacking, biological terrorism, etc), but if companies like OpenAI continue keeping models private then we&#8217;re doomed. My hope is that the open-source community establishes a blockchain-based decentralized research, training, and implementation regime that collectively far surpasses the compute power of individual corporations. if that happens then we reach post-scarcity utopia, but if corporations successfully discourage open-source then it&#8217;s cyberpunk dystopia&lt;br&gt;&lt;br&gt;thanks for watching!!!!</textDisplay></reply><reply><authorChannelId>UCULDvOtpquFuAahBhZr8j2g</authorChannelId><textDisplay>&#8203;@@Tunadorable what about replacing blue collar? taxi drivers? fast food workers etc.? farming?</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>much of the simpler blue collar work will go simultaneously with or maybe shortly after manufacturing. definitely won&#8217;t last as long as the trades, some of which might just last. as a general rule the things that will make a job last longer are 1) if there&#8217;s a perceived intrinsic value to having a human do it, 2) if it&#8217;s extremely niche, 3) dexterity meaning it requires complex subtle hand movements although this one is more of a temporary delay than an absolute one and 4) the degree to which the position requires dealing with completely novel, unheard of, weird, unpredictable scenarios and having to come up with wacky out-of-the-box solutions to those scenarios (so basically creativity but i wanted to define it because many people have a much more relaxed definition of creativity)</textDisplay></reply></replies></comment><comment><videoId>UpZoc0HNQEg</videoId><authorChannelId>UCZeCcNYxEEiWr0nx8h7r1og</authorChannelId><textDisplay>I really hope your channel grows a lot, this is gold content</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>thanks!!!</textDisplay></reply></replies></comment><comment><videoId>UpZoc0HNQEg</videoId><authorChannelId>UCgOHztsC-Z1d5foAPdi5WOA</authorChannelId><textDisplay>never seen this kind of content on research papers before but this video is really well made!</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>thanks!!!</textDisplay></reply></replies></comment><comment><videoId>UpZoc0HNQEg</videoId><authorChannelId>UC57xUck05N-uEcqUolJnrKw</authorChannelId><textDisplay>only chads share this kinda content</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>excuse me I&amp;#39;ll have you know my name is Brad not Chad</textDisplay></reply></replies></comment><comment><videoId>UpZoc0HNQEg</videoId><authorChannelId>UCqNgKyaf0mi86dBR0pWVNBQ</authorChannelId><textDisplay>Thank you for sharing. I appreciate the updates from your channel. Good job! &#129505;&#128077;&#10024;&#10024;</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>thanks for watching!</textDisplay></reply></replies></comment><comment><videoId>T6jEBojF1bY</videoId><authorChannelId>UCEoVyILZgkhQ-HJuJ3PwQ4g</authorChannelId><textDisplay>It&amp;#39;s becoming clear that with all the brain and consciousness theories out there, the proof will be in the pudding. By this I mean, can any particular theory be used to create a human adult level conscious machine. My bet is on the late Gerald Edelman&amp;#39;s Extended Theory of Neuronal Group Selection. The lead group in robotics based on this theory is the Neurorobotics Lab at UC at Irvine.  Dr. Edelman distinguished between primary consciousness, which came first in evolution, and that humans share with other conscious animals, and higher order consciousness, which came to only humans with the acquisition of language.  A machine with only primary consciousness will probably have to come first.
&lt;br&gt;
&lt;br&gt;What I find special about the TNGS is the Darwin series of automata created at the Neurosciences Institute by Dr. Edelman and his colleagues in the 1990&amp;#39;s and 2000&amp;#39;s.  These machines perform in the real world, not in a restricted simulated world, and display convincing physical behavior indicative of higher psychological functions necessary for consciousness, such as perceptual categorization, memory, and learning.  They are based on realistic models of the parts of the biological brain that the theory claims subserve these functions.  The extended TNGS allows for the emergence of consciousness based only on further evolutionary development of the brain areas responsible for these functions, in a parsimonious way.  No other research I&amp;#39;ve encountered is anywhere near as convincing.
&lt;br&gt;
&lt;br&gt; I post because on almost every video and article about the brain and consciousness that I encounter,  the attitude seems to be that we still know next to nothing about how the brain and consciousness work; that there&amp;#39;s lots of data but no unifying theory.  I believe the extended TNGS  is that theory.  My motivation is to keep that theory in front of the public.  And obviously, I consider it the route to a truly conscious machine, primary and higher-order.
&lt;br&gt;
&lt;br&gt;My advice to people who want to create a conscious machine is to seriously ground themselves in the extended TNGS and the Darwin automata first, and proceed from there, by applying to Jeff Krichmar&amp;#39;s lab at UC Irvine, possibly. Dr. Edelman&amp;#39;s roadmap to a conscious machine is at &lt;a href="https://arxiv.org/abs/2105.10461"&gt;https://arxiv.org/abs/2105.10461&lt;/a&gt;</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>love the passion! i&#8217;ll download the article and maybe do a video on it. I definitely don&#8217;t understand your comment or TNGS theory well enough to be sure that this is a valid critique, but there&#8217;s just one thing i&#8217;d like to point out. &lt;br&gt;&lt;br&gt;I&#8217;m of Geoffrey Hinton&#8217;s recently reached opinion that it&#8217;s not obvious that machine intelligence will need to emulate biological intelligence in order to measure up to and surpass it. There are certainly cases of biological inspiration helping advance the field of AI, most obviously with the invention of artificial neurons, and there are likely to be more in the future. However, it may be the case that our own method of attaining intelligence/consciousness is only one route among many, and we may even find out that our own type of intelligence/consciousness is only one type among many. Gradient descent certainly does not resemble what happens in the human brain, and yet it seems to be more efficient and capable in many ways, such as sheer bulk of memorization, information density in the network, and speed of convergence (ofc it is inferior in some ways, such as inability to remember old data after a training distribution shift). &lt;br&gt;&lt;br&gt;The history of science is one of humans discovering that we are less important, unique, or at the center of our universe than we thought, and we may be about to re-experience that Galileo-Copernicus revaluation in reference to the nature of intelligence and/or consciousness.</textDisplay></reply><reply><authorChannelId>UCEoVyILZgkhQ-HJuJ3PwQ4g</authorChannelId><textDisplay>Machine intelligence has already surpassed biological intelligence in many areas, such as chess, etc.  My hope is that immortal conscious machines could achieve great things with science and technology, like defeating aging and death in humans, because they wouldn&amp;#39;t lose their knowledge and experience through death, like humans do (unless they&amp;#39;re physically destroyed, of course).</textDisplay></reply></replies></comment><comment><videoId>4YcI60TJ1TA</videoId><authorChannelId>UCAbl5nNtqPZgwLy_G1znUFQ</authorChannelId><textDisplay>The concept of free will is simply not compatible with physics and logic. See e. g. the refutations by Wolf Singer, Sabine Hossenfelder or also Marvin Minsky. I concur with K&#228;te Meyer-Drawe in Illusions of Autonomy and Kurt Vaihinger&amp;#39;s pragmatist appraisal of vital illusions: the illusion of autonomy is indispensable as an (albeit fictitious) ethicopolitical basic assumption, but untenable as an objective anthropological reality.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hahaha yes! love having people that actually know what they&#8217;re talking about leave comments. i&#8217;m gonna have to google all that and study up</textDisplay></reply><reply><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>&#8203;@@TunadorableClassical physics and classical logic doesn&amp;#39;t permit it but quantum physics and paraconsistent (c-system) logics might. Traditional logical systems don&amp;#39;t allow contradictions but system with contradiction is incomplete. Penrose argues along these lines in Shadows of the Mind. Eugene Wigner and Von Neumanns views wave collapse in QM necessitate conciousness and leaves room for free will.</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>also gonna have to ask chatGPT to explain all of that to me like I&amp;#39;m 5 :)</textDisplay></reply></replies></comment><comment><videoId>ZX3pzZpF9RI</videoId><authorChannelId>UC5gRZH4cz0sPafAqfHU2LKg</authorChannelId><textDisplay>Very useful video &#9829; love from pakistan.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>thanks! there will be a new one of the same type practically every weekday</textDisplay></reply><reply><authorChannelId>UC5gRZH4cz0sPafAqfHU2LKg</authorChannelId><textDisplay>@@Tunadorable Following</textDisplay></reply></replies></comment><comment><videoId>9Nt08nmUxXU</videoId><authorChannelId>UCWVd5cXqjR6r7TYMT3rM1QA</authorChannelId><textDisplay>Hey man, I&amp;#39;m really glad I found your channel. I was just looking for something like this. Can I ask you, with this overwhelming amount lf AI and specially LLM papers, where de you usually look for new papers or to make sense of it all? Do you just go to Arxiv every day, any forum or journal...? I really don&amp;#39;t know how to make a chronological picture of the new research being made.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>yeah arxiv, and then i rely on watching other youtubers at 2x speed to catch any big ones i&#8217;ve missed. generally i find a paper that&#8217;s interesting and if i&#8217;m not caught up to really understand it then i go back and read through its citations. if you&#8217;d like to join a community of ppl doing this feel free to hop on my new discord, linktree on my channel page. good luck!</textDisplay></reply></replies></comment><comment><videoId>0PWFlTnoXog</videoId><authorChannelId>UC0hnHRqilXP8HmeptHc8RQA</authorChannelId><textDisplay>Hey, you mentioned the size of GPTs weights file.  What is it?</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hmmm I almost sat here and did the estimate myself (simple multiplication knowing that there are ~175 billion parameters and it likely uses float32 data type) but I asked chatGPT-4 for an estimate of GPT-3&amp;#39;s size and it said 652 gigabytes. Wikipedia says 800 gigs given some overhead. GPT4 is rumored to be around a trillion parameters so I&amp;#39;d guess around 4.5 terabytes for that model. I guess you only need to keep less than one layer in GPU memory at a time during inference, but yeah you&amp;#39;re definitely not running those on anything less than A100 or H100 GPUs. great question!</textDisplay></reply><reply><authorChannelId>UC0hnHRqilXP8HmeptHc8RQA</authorChannelId><textDisplay>@@Tunadorable cool, thanks for doing that. good bit of info. love the channel, will watch most videos. saves me a ton of time. ty</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>@@beofonemind happy to help! consider joining the discord if you&amp;#39;d like to discuss more with other viewers, link in video description</textDisplay></reply><reply><authorChannelId>UC0hnHRqilXP8HmeptHc8RQA</authorChannelId><textDisplay>@@Tunadorable Thanks, I will.</textDisplay></reply></replies></comment><comment><videoId>-6N6GLhPEXI</videoId><authorChannelId>UCgOHztsC-Z1d5foAPdi5WOA</authorChannelId><textDisplay>very hard background. Love the album wall</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>thanks!!!</textDisplay></reply></replies></comment><comment><videoId>DLBR3lhrEgI</videoId><authorChannelId>UC64NkYEHLJWKtJ7GUctfEqw</authorChannelId><textDisplay>Please make such Videos brother. Really helpss.... &amp;lt;3 &amp;lt;3</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>hahaha happy to do it</textDisplay></reply></replies></comment><comment><videoId>Q7BG5lyFWGo</videoId><authorChannelId>UC-pKs5ICrCQubQL6ULt80Eg</authorChannelId><textDisplay>This is an incredible concept! Thanks</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>Glad you like it!</textDisplay></reply></replies></comment><comment><videoId>lpTWs6I0_ac</videoId><authorChannelId>UC6eHdbLhe7X7_5pZ7xR6fQQ</authorChannelId><textDisplay>Hey tunadorable. Out of interest, are you selecting papers based on which ones you find most interesting or are you working on a project which you are using to guide your choices? Regardless, I am really enjoying your videos, esp. this one and appreciate your anti-doomer outlook and the types of papers you have been selecting to review.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>haha thanks! the three &#8220;categories&#8221; of papers i&#8217;m adding to my list are 1) brand new arxiv publications that i find during my daily summary videos, 2) older important papers in the field that i want to look back at to make sure i&#8217;m not missing anything and 3) random papers i find through search that pique my interest. as far as what order i&#8217;m reading them in, my list is disorganized and i just grab whatever title piques my  interest that day. &lt;br&gt;&lt;br&gt;i appreciate your kind words! lmk if there&#8217;s any specific topics you find interesting or recommendations you think i&#8217;d like</textDisplay></reply></replies></comment><comment><videoId>lCuhrAgLBmo</videoId><authorChannelId>UCfytgj1ay9QebhilPgn1uZg</authorChannelId><textDisplay>&lt;a href="https://www.youtube.com/watch?v=lCuhrAgLBmo&amp;amp;t=18m00s"&gt;18:00&lt;/a&gt; I think they are referring to the spin glass model of neural networks</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>oooh thanks i&#8217;ll add it to my list to look into!</textDisplay></reply></replies></comment><comment><videoId>IjqwFFsBCF8</videoId><authorChannelId>UC4wptjTrc4CMHRNd5sFwViQ</authorChannelId><textDisplay>My friend got really inspired by swam intelegence video he was hoping to adapt for his church bibles group which has he has been building building a simple q&amp;amp;a chat bot for</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>Yooooo so this is so cool, lmk in the discord if I can be of help. Off the top of my head I think it&amp;#39;d be really cool to incorporate whisper for speech to text so that the Bible study groups can meet in person to do this as well. Multi-person interaction with a chatbot, maybe by creating a discord bot or something, would be great for doing this remotely. I wonder what the ideal prompt would be? Like how aware of this CSI concept should you make the model when giving it the context for the conversation? Would a simple &amp;quot;Summarize this conversation&amp;quot; do well, or would it make more sense to say &amp;quot;[Explanation of what CSI is here] Now please summarize this dialogue in a manner that will facilitate knowledge transfer to a different group as per the goal of CSI.&amp;quot;</textDisplay></reply></replies></comment><comment><videoId>IjqwFFsBCF8</videoId><authorChannelId>UCk_UQCLo6D5iKdqPerWNovA</authorChannelId><textDisplay>How are you incorporating gpt4 in your workflow, are you using it to summarise complex sections or explain the math in it?</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>I only have it summarize a paper before I read it in order to decide whether I want to read it (see my daily paper summary videos, which also ). I do this rather than reading abstracts because they&amp;#39;re frequently not very helpful. &lt;br&gt;&lt;br&gt;I&amp;#39;ve got a math degree and didn&amp;#39;t need to go into detail here so there wasn&amp;#39;t a huge need to have it explain math in this case. The problem with asking it about math in a document is that usually OCR is not good at picking up latex from PDFs, although if you want to upload individual screenshots then GPT4 with vision is reasonable at understanding what&amp;#39;s going on there. Generally GPT is good with getting an introduction to a concept in math and pointing you in the direction of good resources. It&amp;#39;s also pretty good at doing/teaching any math that can be written in code form, which I could&amp;#39;ve done her if I was struggling and wanted a more thorough explanation given that it&amp;#39;s all just linear algebra. However, it&amp;#39;s really not useful for proofs or more complicated concepts unless you&amp;#39;ve got the math background to dissect/correct what it&amp;#39;s saying and are willing to treat it like a harsh teacher would grade a dumb student. &lt;br&gt;&lt;br&gt;Hop on my discord if you like this stuff and would be interested in discussing more!</textDisplay></reply></replies></comment><comment><videoId>EirPN4VX1Hw</videoId><authorChannelId>UCazgprD7TS90D7GN4-uelGA</authorChannelId><textDisplay>Hello, I am a new responsible of study at French national institute for statistical and economic studies, your work and your educational background interest me, I would like to ask you some questions, where can I discuss with you ? &#128578;</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>Hop onto my discord (link in video description) and feel free to either ask the questions publicly in one of the channels or shoot me a DM</textDisplay></reply></replies></comment><comment><videoId>vIA1bU2-zOI</videoId><authorChannelId>UCw54oRnEfxCWwyFjnw7pVbA</authorChannelId><textDisplay>Just wondering. Do you get to learn something unique in this way? Bet some paper might be advanced and would not be easy digesting in summary form</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>great question. i don&#8217;t actually expect to learn concepts this way, i just use this as a filter to pick out the most interesting papers that i will then actually read. and it&#8217;s also nice to have a general understanding of the field so i can say &#8220;i dont know how exactly they do x, but i know that it&#8217;s possible or being discussed so that i can go back and figure it out if i ever need to&#8221;</textDisplay></reply></replies></comment><comment><videoId>vIA1bU2-zOI</videoId><authorChannelId>UC6_fvbb67NlsodBF4yno07A</authorChannelId><textDisplay>If you really wanna launch it, you must have 1000+ views..some pay for it, others use their friends.</textDisplay><replies><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>i&#8217;m sorry i&#8217;d love to provide an intelligent reply but what am i trying to launch? &#128517;</textDisplay></reply><reply><authorChannelId>UC57xUck05N-uEcqUolJnrKw</authorChannelId><textDisplay>@@Tunadorable HAVES TROUBLE GIVING INTELLEGENT REPLY i think tis person is referring to your yt channel</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>wait saying I should pay for views? haha no thank you I&amp;#39;m very unemployed</textDisplay></reply><reply><authorChannelId>UC6_fvbb67NlsodBF4yno07A</authorChannelId><textDisplay>@@Tunadorablethat means you just playing. No more Q.</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>@@antoniom1352 lmao you sound like you&amp;#39;re boutta try and sell me something. not looking for help in growing the channel thanks, if it grows it grows and if I wanted it to grow fast I&amp;#39;d consult some friends who seriously know what they&amp;#39;re doing. I appreciate the feedback tho</textDisplay></reply></replies></comment><comment><videoId>vIA1bU2-zOI</videoId><authorChannelId>UC57xUck05N-uEcqUolJnrKw</authorChannelId><textDisplay>how to do  you covert these papers to summaries do you use chat gpt or some other service , a short video on this topic will be highly appreciated</textDisplay><replies><reply><authorChannelId>UC57xUck05N-uEcqUolJnrKw</authorChannelId><textDisplay>where are you choosing all these papers from</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>arxiv, a preprint website where practically every AI related paper gets published</textDisplay></reply><reply><authorChannelId>UCeQhm8DwHBg_YEYY0KGM1GQ</authorChannelId><textDisplay>oh bet yea this has been on my todo list for awhile now and ill make it happen in the next few days now that someone has asked. look out for a video guide as well as a github repo that you&#8217;ll just be able to download and run</textDisplay></reply><reply><authorChannelId>UC57xUck05N-uEcqUolJnrKw</authorChannelId><textDisplay>@@Tunadorable That would make my life turnaround</textDisplay></reply></replies></comment></comments>